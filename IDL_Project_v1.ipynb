{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexfok/IntroDeepLearning2022/blob/main/IDL_Project_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alexander Fok 308669944\n",
        "\n",
        "Avi Dvir 204423735\n",
        "\n",
        "Gal Cohen 204675805"
      ],
      "metadata": {
        "id": "L-g8kqS38eFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project: Unsupervised Deep Embedding for Clustering Analysis\n",
        "\n",
        "**Assignment Responsible**: May Malka.\n",
        "\n",
        "In this project, we build a Unsupervised Deep Embedding for Clustering Analysis with AE, etc \n"
      ],
      "metadata": {
        "datalore": {
          "node_id": "rUtqtpumeGiU9qSgLSWIsq",
          "type": "MD",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {}
        },
        "id": "iBhIe_rQ-LBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#!pip install leveldb\n",
        "#!pip install features\n",
        "!pip install scipy\n",
        "import leveldb\n",
        "import shutil\n",
        "import random\n",
        "#import features\n",
        "from joblib import Parallel, delayed\n",
        "#from skimage import feature\n",
        "from skimage.feature import hog\n",
        "import multiprocessing\n",
        "#from scipy.misc import imrotate\n",
        "import scipy\n",
        "\n",
        "# Run NN and torch data on GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Notebook Control variables\n",
        "# Print DEBUG info\n",
        "DEBUG = False\n",
        "# Variable controlling debug prints while training\\infering with NN\n",
        "DEBUG_NN = False\n",
        "# Create the data sets or load the preloaded np arrays\n",
        "CREATE_DATA = True\n",
        "# Path to save the created numpy arrays\n",
        "array_save_path = '/content/gdrive/My Drive/IntroDeepLearning2022Data/project/data.npy'\n",
        "# Path to load the created numpy arrays\n",
        "array_load_path = '/content/gdrive/My Drive/IntroDeepLearning2022Data/project/data.npy.npz'\n",
        "best_model_path = '/content/gdrive/MyDrive/IntroDeepLearning2022Data/project/model_chkpt_epoch_20.pk'\n",
        "checkpoint_path = '/content/gdrive/MyDrive/IntroDeepLearning2022Data/project/model_chkpt_epoch_{}.pk'\n",
        "\n",
        "# Raw data set paths\n",
        "path_train = \"/content/gdrive/My Drive/IntroDeepLearning2022Data/project\"\n",
        "#path_train = \"/content/gdrive/My Drive/IntroDeepLearning2022Data/data/train/*.*\"\n",
        "#path_test_m = \"/content/gdrive/My Drive/IntroDeepLearning2022Data/data/test_m/*.*\"\n",
        "#path_test_w = \"/content/gdrive/My Drive/IntroDeepLearning2022Data/data/test_w/*.*\"\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy) (1.21.6)\n"
          ]
        }
      ],
      "metadata": {
        "datalore": {
          "node_id": "Ah4GlVbbAIFKEVViWTgJBk",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {}
        },
        "id": "sYk9_VGc-LB5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdc68e90-17d9-49f7-9964-80224e7eaec8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Load\n",
        "\n",
        "Download the data from https://www.dropbox.com/s/6gdcpmfddojrl8o/data.rar?dl=0.\n",
        "\n",
        "Unzip the file. There are three\n",
        "main folders: `train`, `test_w` and `test_m`. Data in `train` will be used for\n",
        "training and validation, and the data in the other folders will be used for testing.\n",
        "This is so that the entire class will have the same test sets. The dataset is comprised of triplets of pairs, where each such triplet of image pairs was taken in a similar setting (by the same person).\n",
        "\n",
        "We've separated `test_w` and `test_m` so that we can track our model performance \n",
        "for women's shoes and men's shoes separately. Each of the test sets contain images of either exclusively men's shoes or women's\n",
        "shoes.\n",
        "\n",
        "Upload this data to Google Colab.\n",
        "Then, mount Google Drive from your Google Colab notebook:"
      ],
      "metadata": {
        "datalore": {
          "node_id": "iwTIBTefYd7Hx4VzEIUAjs",
          "type": "MD",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {}
        },
        "id": "Cgr-3qFM-LB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "metadata": {
        "datalore": {
          "node_id": "eLDlDXFSkWiHx6Wbv7fwUE",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {}
        },
        "id": "FziBXGJT-LB-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48d0acfb-bbce-4c53-a37f-a5adb852576f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "datalore": {
          "node_id": "zxw4NgPD9PJ4BaiYqUpMfH",
          "type": "MD",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {}
        },
        "id": "gwOB-Lan-LB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (a)\n"
      ],
      "metadata": {
        "datalore": {
          "node_id": "0Y652e87nWFEZO8504Yb8y",
          "type": "MD",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {}
        },
        "id": "YXFytiLg-LB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "!ls -laht *-ubyte\n",
        "#!pwd\n",
        "!cp train-labels-idx1-ubyte \"$path_train\"\n",
        "!cp train-images-idx3-ubyte \"$path_train\"\n",
        "!cp t10k-labels-idx1-ubyte \"$path_train\"\n",
        "!cp t10k-images-idx3-ubyte \"$path_train\"\n",
        "#!cp *-ubyte \"$path_train\"\n",
        "#!cp ./*-ubyte \"$path_train\"/*\n",
        "\n",
        "#!cp './train-images-idx3-ubyte' '$path_train'\n",
        "#path_train='test'\n",
        "!echo \"$path_train\"\n",
        "'''\n",
        "#!tar -xf stl10_binary.tar.gz\n",
        "!ls -laht .\n",
        "!ls -laht stl10_binary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjvkHkkGCNxW",
        "outputId": "8c7c2cdd-c7aa-4687-d929-cd9bad07f6e9"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 2.6G\n",
            "-rw-r--r-- 1 root  root 513K Dec 28 15:08 train_X.bin_org.jpg\n",
            "drwxr-xr-x 1 root  root 4.0K Dec 28 13:26 .\n",
            "drwx------ 6 root  root 4.0K Dec 28 12:10 gdrive\n",
            "drwxr-xr-x 1 root  root 4.0K Dec 28 12:05 ..\n",
            "drwxr-xr-x 1 root  root 4.0K Dec 20 20:19 sample_data\n",
            "drwxr-xr-x 4 root  root 4.0K Dec 20 20:18 .config\n",
            "-rw-r--r-- 1 root  root 2.5G Apr  8  2011 stl10_binary.tar.gz\n",
            "drwxr-xr-x 2 10176 1000 4.0K Apr  8  2011 stl10_binary\n",
            "-rw-r--r-- 1 root  root  59K Jul 21  2000 train-labels-idx1-ubyte\n",
            "-rw-r--r-- 1 root  root  45M Jul 21  2000 train-images-idx3-ubyte\n",
            "-rw-r--r-- 1 root  root 9.8K Jul 21  2000 t10k-labels-idx1-ubyte\n",
            "-rw-r--r-- 1 root  root 7.5M Jul 21  2000 t10k-images-idx3-ubyte\n",
            "total 3.0G\n",
            "drwxr-xr-x 1 root  root  4.0K Dec 28 13:26 ..\n",
            "drwxr-xr-x 2 10176  1000 4.0K Apr  8  2011 .\n",
            "-rw-r--r-- 1 10176 users 7.9K Apr  8  2011 test_y.bin\n",
            "-rw-r--r-- 1 10176 users 211M Apr  8  2011 test_X.bin\n",
            "-rw-r--r-- 1 10176 users 132M Apr  8  2011 train_X.bin\n",
            "-rw-r--r-- 1 10176 users 4.9K Apr  8  2011 train_y.bin\n",
            "-rw-r--r-- 1 10176 users  47K Apr  8  2011 fold_indices.txt\n",
            "-rw-r--r-- 1 10176 users 2.6G Mar 16  2011 unlabeled_X.bin\n",
            "-rw-r--r-- 1 10176  1000   55 Mar 16  2011 class_names.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/sh\n",
        "# Download data set and save it on GDrive\n",
        "# MNIST dataset\n",
        "!wget http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
        "!gunzip -f train-images-idx3-ubyte.gz\n",
        "!wget http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
        "!gunzip -f train-labels-idx1-ubyte.gz\n",
        "!wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
        "!gunzip -f t10k-images-idx3-ubyte.gz\n",
        "!wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
        "!gunzip -f t10k-labels-idx1-ubyte.gz\n",
        "\n",
        "#!cp ./*-ubyte \"$path_train\"\n",
        "!cp train-labels-idx1-ubyte \"$path_train\"\n",
        "!cp train-images-idx3-ubyte \"$path_train\"\n",
        "!cp t10k-labels-idx1-ubyte \"$path_train\"\n",
        "!cp t10k-images-idx3-ubyte \"$path_train\"\n",
        "\n",
        "# STL dataset\n",
        "!wget http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz\n",
        "!tar -xf stl10_binary.tar.gz\n",
        "!ls -la\n",
        "#!cp './train-images-idx3-ubyte' \"$path_train\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fPsxnCQAz8V",
        "outputId": "6e8f6ef5-30e3-4f1d-ad64-80d6485e2c13"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-28 13:00:34--  http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 172.67.171.76, 104.21.29.36, 2606:4700:3036::ac43:ab4c, ...\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|172.67.171.76|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9912422 (9.5M) [application/x-gzip]\n",
            "Saving to: ‘train-images-idx3-ubyte.gz’\n",
            "\n",
            "\r          train-ima   0%[                    ]       0  --.-KB/s               \rtrain-images-idx3-u 100%[===================>]   9.45M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2022-12-28 13:00:34 (111 MB/s) - ‘train-images-idx3-ubyte.gz’ saved [9912422/9912422]\n",
            "\n",
            "--2022-12-28 13:00:35--  http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 172.67.171.76, 104.21.29.36, 2606:4700:3036::ac43:ab4c, ...\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|172.67.171.76|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28881 (28K) [application/x-gzip]\n",
            "Saving to: ‘train-labels-idx1-ubyte.gz’\n",
            "\n",
            "train-labels-idx1-u 100%[===================>]  28.20K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-12-28 13:00:35 (385 MB/s) - ‘train-labels-idx1-ubyte.gz’ saved [28881/28881]\n",
            "\n",
            "--2022-12-28 13:00:35--  http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 172.67.171.76, 104.21.29.36, 2606:4700:3036::ac43:ab4c, ...\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|172.67.171.76|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1648877 (1.6M) [application/x-gzip]\n",
            "Saving to: ‘t10k-images-idx3-ubyte.gz’\n",
            "\n",
            "t10k-images-idx3-ub 100%[===================>]   1.57M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-12-28 13:00:35 (144 MB/s) - ‘t10k-images-idx3-ubyte.gz’ saved [1648877/1648877]\n",
            "\n",
            "--2022-12-28 13:00:35--  http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 172.67.171.76, 104.21.29.36, 2606:4700:3036::ac43:ab4c, ...\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|172.67.171.76|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4542 (4.4K) [application/x-gzip]\n",
            "Saving to: ‘t10k-labels-idx1-ubyte.gz’\n",
            "\n",
            "t10k-labels-idx1-ub 100%[===================>]   4.44K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-12-28 13:00:35 (501 MB/s) - ‘t10k-labels-idx1-ubyte.gz’ saved [4542/4542]\n",
            "\n",
            "--2022-12-28 13:00:36--  http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2640397119 (2.5G) [application/x-gzip]\n",
            "Saving to: ‘stl10_binary.tar.gz’\n",
            "\n",
            "stl10_binary.tar.gz 100%[===================>]   2.46G  16.0MB/s    in 2m 44s  \n",
            "\n",
            "2022-12-28 13:03:21 (15.3 MB/s) - ‘stl10_binary.tar.gz’ saved [2640397119/2640397119]\n",
            "\n",
            "tar: --strip=1: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "total 2632212\n",
            "drwxr-xr-x 1 root root       4096 Dec 28 13:00 .\n",
            "drwxr-xr-x 1 root root       4096 Dec 28 12:05 ..\n",
            "drwxr-xr-x 4 root root       4096 Dec 20 20:18 .config\n",
            "drwx------ 6 root root       4096 Dec 28 12:10 gdrive\n",
            "drwxr-xr-x 1 root root       4096 Dec 20 20:19 sample_data\n",
            "-rw-r--r-- 1 root root 2640397119 Apr  8  2011 stl10_binary.tar.gz\n",
            "-rw-r--r-- 1 root root    7840016 Jul 21  2000 t10k-images-idx3-ubyte\n",
            "-rw-r--r-- 1 root root      10008 Jul 21  2000 t10k-labels-idx1-ubyte\n",
            "-rw-r--r-- 1 root root   47040016 Jul 21  2000 train-images-idx3-ubyte\n",
            "-rw-r--r-- 1 root root      60008 Jul 21  2000 train-labels-idx1-ubyte\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dispImg(X, n, fname=None):\n",
        "  h = X.shape[1]\n",
        "  w = X.shape[2]\n",
        "  c = X.shape[3]\n",
        "  buff = np.zeros((n*w, n*w, c), dtype=np.uint8)\n",
        "\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      buff[i*h:(i+1)*h, j*w:(j+1)*w, :] = X[i*n+j]\n",
        "\n",
        "  if fname is None:\n",
        "    cv2.imshow('a', buff)\n",
        "    cv2.waitKey(0)\n",
        "  else:\n",
        "    cv2.imwrite(fname, buff)\n",
        "\n",
        "def hog_picture(hog, resolution):\n",
        "#    from scipy.misc import imrotate\n",
        "    glyph1 = np.zeros((resolution, resolution), dtype=np.uint8)\n",
        "    glyph1[:, round(resolution / 2)-1:round(resolution / 2) + 1] = 255\n",
        "    glyph = np.zeros((resolution, resolution, 9), dtype=np.uint8)\n",
        "    glyph[:, :, 0] = glyph1\n",
        "    for i in range(1, 9):\n",
        "        tt = scipy.ndimage.interpolation.rotate(glyph1, -i * 20)\n",
        "        tt = cv2.resize(tt, (resolution, resolution), interpolation = cv2.INTER_AREA)\n",
        "        glyph[:, :, i] = tt\n",
        "#        glyph[:, :, i] = imrotate(glyph1, -i * 20)\n",
        "\n",
        "#    print(f'tt.shape: {tt.shape}')\n",
        "    print(f'hog.shape: {hog.shape}')\n",
        "    shape = hog.shape\n",
        "    clamped_hog = hog.copy()\n",
        "    clamped_hog[hog < 0] = 0\n",
        "    image = np.zeros((resolution * shape[0], resolution * shape[1]), dtype=np.float32)\n",
        "    for i in range(shape[0]):\n",
        "        for j in range(shape[1]):\n",
        "            for k in range(9):\n",
        "                image[i*resolution:(i+1)*resolution, j*resolution:(j+1)*resolution] = np.maximum(image[i*resolution:(i+1)*resolution, j*resolution:(j+1)*resolution], clamped_hog[i, j, k] * glyph[:, :, k])\n",
        "\n",
        "    return image\n",
        "\n",
        "def read_db(str_db, float_data = True):\n",
        "    db = leveldb.LevelDB(str_db)\n",
        "    datum = caffe_pb2.Datum()\n",
        "    array = []\n",
        "    label = []\n",
        "    for k,v in db.RangeIter():\n",
        "        dt = datum.FromString(v)\n",
        "        if float_data:\n",
        "          array.append(dt.float_data)\n",
        "        else: \n",
        "          array.append(np.fromstring(dt.data, dtype=np.uint8))\n",
        "        label.append(dt.label)\n",
        "    return np.asarray(array), np.asarray(label)\n",
        "\n",
        "def write_db(X, Y, fname):\n",
        "    if os.path.exists(fname):\n",
        "      shutil.rmtree(fname)\n",
        "    assert X.shape[0] == Y.shape[0]\n",
        "    X = X.reshape((X.shape[0], X.size/X.shape[0], 1, 1))\n",
        "    db = leveldb.LevelDB(fname)\n",
        "\n",
        "    for i in range(X.shape[0]):\n",
        "      x = X[i]\n",
        "      if x.ndim != 3:\n",
        "        x = x.reshape((x.size,1,1))\n",
        "      db.Put('{:08}'.format(i), caffe.io.array_to_datum(x, int(Y[i])).SerializeToString())\n",
        "#      print(np.array2string(x, int(Y[i])))\n",
        "    del db\n",
        "\n",
        "def load_mnist(root, training):\n",
        "  if training:\n",
        "    data = 'train-images-idx3-ubyte'\n",
        "    label = 'train-labels-idx1-ubyte'\n",
        "    N = 60000\n",
        "  else:\n",
        "    data = 't10k-images-idx3-ubyte'\n",
        "    label = 't10k-labels-idx1-ubyte'\n",
        "    N = 10000\n",
        "  with open(root+data, 'rb') as fin:\n",
        "    fin.seek(16, os.SEEK_SET)\n",
        "    X = np.fromfile(fin, dtype=np.uint8).reshape((N,28*28))\n",
        "  with open(root+label, 'rb') as fin:\n",
        "    fin.seek(8, os.SEEK_SET)\n",
        "    Y = np.fromfile(fin, dtype=np.uint8)\n",
        "  return X, Y\n",
        "\n",
        "def make_mnist_data():\n",
        "  X, Y = load_mnist('./', True)\n",
        "  X_ = X.astype(np.float64)*0.02\n",
        "#  X = X.astype(np.float64)*0.02\n",
        "#  write_db(X, Y, 'mnist_train')\n",
        "\n",
        "#  X_, Y_ = read_db('mnist_train', True)\n",
        "#  assert np.abs((X - X_)).mean() < 1e-5\n",
        "#  assert (Y != Y_).sum() == 0\n",
        "\n",
        "  X2, Y2 = load_mnist('./', False)\n",
        "  X2 = X2.astype(np.float64)*0.02\n",
        "#  write_db(X2, Y2, 'mnist_test')\n",
        "\n",
        "  X3 = np.concatenate((X,X2), axis=0)\n",
        "  Y3 = np.concatenate((Y,Y2), axis=0)\n",
        "#  write_db(X3,Y3, 'mnist_total')\n",
        "  return X, Y\n",
        "\n",
        "def load_stl(fname):\n",
        "  num_core=multiprocessing.cpu_count()\n",
        "\n",
        "  X = np.fromfile('./stl10_binary/'+fname, dtype=np.uint8)\n",
        "  print(f'fname: {fname}')\n",
        "  X = X.reshape((-1, 3, 96, 96)).transpose((0,3,2,1))\n",
        "#  images = np.reshape(everything, (-1, 3, 96, 96))\n",
        "#  images = np.transpose(images, (0, 3, 2, 1))\n",
        "  print(f'X.shape: {X.shape}')\n",
        "  global GH\n",
        "\n",
        "  dispImg(X[:100, :, :, [2,1,0]], 10, fname+'_org.jpg')\n",
        "\n",
        "  n_jobs = num_core # 10\n",
        "  cmap_size = (8,8)\n",
        "  N = X.shape[0]\n",
        "\n",
        "  H = np.asarray(\n",
        "      Parallel(n_jobs=n_jobs)\\\n",
        "      (delayed(hog)\\\n",
        "      (X[i], orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), block_norm=\"L2\", transform_sqrt=True, feature_vector=True)\n",
        "      for i in range(N))\n",
        "      )\n",
        "#  H = np.asarray(Parallel(n_jobs=n_jobs)(delayed(feature.hog)(X[i]) for i in range(N)))\n",
        "#  for i in range(N):\n",
        "#    H = hog(X[i], orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), block_norm=\"L2\", transform_sqrt=True, feature_vector=True)\n",
        "\n",
        "  print(f'H.shape: {H.shape}, H.size: {H.size}')\n",
        "  print(f'H[0]: {H[0]}')\n",
        "#  fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),\n",
        "#                    cells_per_block=(1, 1), visualize=True, channel_axis=-1)\n",
        "  GH = H\n",
        "  H_img = np.repeat(np.asarray([ hog_picture(H[i], 9) for i in range(100) ])[:, :,:,np.newaxis], 3, 3)\n",
        "  dispImg(H_img, 10, fname+'_hog.jpg') \n",
        "  H = H.reshape((H.shape[0], H.size/N))\n",
        "\n",
        "  X_small = np.asarray(Parallel(n_jobs=n_jobs)( delayed(cv2.resize)(X[i], cmap_size) for i in range(N) ))\n",
        "  crcb = np.asarray(Parallel(n_jobs=n_jobs)( delayed(cv2.cvtColor)(X_small[i], cv.CV_RGB2YCrCb) for i in range(N) ))\n",
        "  crcb = crcb[:,:,:,1:]\n",
        "  crcb = crcb.reshape((crcb.shape[0], crcb.size/N))\n",
        "\n",
        "  feature = np.concatenate(((H-0.2)*10.0, (crcb-128.0)/10.0), axis=1)\n",
        "  print(feature.shape)\n",
        "\n",
        "  return feature, X[:,:,:,[2,1,0]]\n",
        "\n",
        "\n",
        "def make_stl_data():\n",
        "  np.random.seed(1234)\n",
        "  random.seed(1234)\n",
        "  X_train, img_train = load_stl('train_X.bin')\n",
        "  X_test, img_test = load_stl('test_X.bin')\n",
        "  X_unlabel, img_unlabel = load_stl('unlabeled_X.bin')\n",
        "  Y_train = np.fromfile('./stl10_binary/train_y.bin', dtype=np.uint8) - 1\n",
        "  Y_test = np.fromfile('./stl10_binary/test_y.bin', dtype=np.uint8) - 1\n",
        "\n",
        "  X_total = np.concatenate((X_train, X_test), axis=0)\n",
        "  img_total = np.concatenate((img_train, img_test), axis=0)\n",
        "  Y_total = np.concatenate((Y_train, Y_test))\n",
        "  p = np.random.permutation(X_total.shape[0])\n",
        "  X_total = X_total[p]\n",
        "  img_total = img_total[p]\n",
        "  Y_total = Y_total[p]\n",
        "  write_db(X_total, Y_total, 'stl_total')\n",
        "  write_db(img_total, Y_total, 'stl_img')\n",
        "\n",
        "  X = np.concatenate((X_total, X_unlabel), axis=0)\n",
        "  p = np.random.permutation(X.shape[0])\n",
        "  X = X[p]\n",
        "  Y = np.zeros((X.shape[0],))\n",
        "  N = X.shape[0]*4/5\n",
        "  write_db(X[:N], Y[:N], 'stl_train')\n",
        "  write_db(X[N:], Y[N:], 'stl_test')\n",
        "\n",
        "GH\n",
        "print(f'GH.shape[0], int(GH.size/5000): {GH.shape[0]}, {int(GH.size/5000)}')\n",
        "GH = GH.reshape((GH.shape[0], int(GH.size/5000)))\n",
        "#make_mnist_data()\n",
        "#GH = make_stl_data()\n",
        "#for i in range(100):\n",
        "#  hog_picture(GH[i], 9)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-5mfjgyoX_S",
        "outputId": "b8a34f8d-cae8-4afa-cb60-a861f6b7eb30"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GH.shape[0], int(GH.size/5000): 5000, 4356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here. Make sure it does not get cut off\n",
        "# You can use the code below to help you get started. You're welcome to modify\n",
        "# the code or remove it entirely: it's just here so that you don't get stuck\n",
        "# reading files\n",
        "\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Save numpy arrays\n",
        "def save_numpy_arrays(array_save_path, train_data, test_w_data, test_m_data):\n",
        "  np.savez(array_save_path, train_data = train_data, test_m_data = test_m_data, test_w_data = test_w_data)\n",
        "\n",
        "# Load numpy arrays\n",
        "def load_numpy_arrays(array_load_path):\n",
        "  train_data = None\n",
        "  test_m_data = None\n",
        "  test_w_data = None\n",
        "  data = np.load(array_load_path, allow_pickle = True)\n",
        "  train_data = data['train_data']\n",
        "  test_m_data = data['test_m_data']\n",
        "  test_w_data = data['test_m_data']\n",
        "  if DEBUG:\n",
        "    print(f'data.files {data.files}')\n",
        "    print(f'train_data.shape {train_data.shape}')\n",
        "    print(f'test_w_data.shape {test_w_data.shape}')\n",
        "    print(f'test_m_data.shape {test_m_data.shape}')\n",
        "  return train_data, test_w_data, test_m_data\n",
        "\n",
        "\n",
        "# Load images to numpy arrays\n",
        "def load_images(path):\n",
        "  images = dict()\n",
        "  # find number of unique persons in data set\n",
        "  person_index = -1\n",
        "  active_person = None\n",
        "  for file in tqdm(sorted(glob.glob(path))):\n",
        "    filename = file.split(\"/\")[-1]   # get the name of the .jpg file\n",
        "    person_n, shoe, leg, _ = filename.split(\"_\")\n",
        "    if active_person != person_n: # Increment person index each time new person detected\n",
        "      person_index += 1\n",
        "      active_person = person_n\n",
        "    if DEBUG:\n",
        "      print(f'person_index: {person_index} active_person: {active_person} person_n: {person_n}')\n",
        "  print(f'Total person_index: {person_index}')\n",
        "\n",
        "  # Allocate the np array according to found number of unique persons in data set\n",
        "  train_data_np = np.empty((person_index+1, 3, 2, 224, 224, 3))\n",
        "  person_index = -1\n",
        "  active_person = None\n",
        "  for file in tqdm(sorted(glob.glob(path))):\n",
        "    filename = file.split(\"/\")[-1]   # get the name of the .jpg file\n",
        "    img = plt.imread(file)           # read the image as a numpy array\n",
        "    images[filename] = img[:, :, :3] # remove the alpha channel\n",
        "\n",
        "    person_n, shoe, leg, _ = filename.split(\"_\")\n",
        "    if active_person != person_n: # Increment person index each time new person detected\n",
        "      person_index += 1\n",
        "      active_person = person_n\n",
        "    if DEBUG:\n",
        "      print(f'person_index: {person_index} active_person: {active_person} person_n: {person_n}')\n",
        "    shoe_n = int(shoe)\n",
        "    shoe_n -= 1                     # Start shoe index from 0\n",
        "    leg = 1 if leg == 'right' else 0\n",
        "    train_data_np[person_index, shoe_n, leg,:,:,:] = images[filename]\n",
        "  return train_data_np\n",
        "\n",
        "def create_and_save_data(array_save_path):\n",
        "  # Load images for train, test_w and test_m data sets\n",
        "  train_data = load_images(path_train)\n",
        "  test_w_data = load_images(path_test_w)\n",
        "  test_m_data = load_images(path_test_m)\n",
        "\n",
        "  # Process the loaded data\n",
        "  # Divide data by 255\n",
        "  train_data /= 255.0\n",
        "  test_w_data /= 255.0\n",
        "  test_m_data /= 255.0\n",
        "\n",
        "  # Subtract 0.5\n",
        "  train_data -= 0.5\n",
        "  test_w_data -= 0.5\n",
        "  test_m_data -= 0.5\n",
        "\n",
        "  # Save the data sets for future use\n",
        "  save_numpy_arrays(array_save_path, train_data, test_w_data, test_m_data)\n",
        "  return train_data, test_w_data, test_m_data\n",
        "\n",
        "if DEBUG:\n",
        "  sample_image = train_data_np[0,0,0,:,:,:]\n",
        "  plt.figure()\n",
        "  plt.imshow(sample_image)\n",
        "  images[4,0,0,:,:,:]"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "LRJHeH7PWHwVXflhOi59Ql",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {}
        },
        "id": "XpVWXKIV-LCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# These data sets will be initialized at the end of this cell\n",
        "train_data = None\n",
        "test_m_data = None\n",
        "test_w_data = None\n",
        "valid_set = None\n",
        "train_set = None\n",
        "\n",
        "if CREATE_DATA:\n",
        "  # Create and save data sets\n",
        "  print('Create numpy arrays from raw data sets and save to GDrive')\n",
        "  train_data, test_w_data, test_m_data = create_and_save_data(array_save_path)\n",
        "else:\n",
        "  print('Load the numpy arrays from GDrive')\n",
        "  # Load the data files and initiate global variables:\n",
        "  # train_data, test_m_data, test_w_data, valid_set, train_set\n",
        "  # Verify that data file exists\n",
        "  # !ls -la '/content/gdrive/My Drive/IntroDeepLearning2022Data/ex3'\n",
        "  train_data, test_w_data, test_m_data = load_numpy_arrays(array_load_path)\n",
        "  # Split training data to training and validation\n",
        "\n",
        "# Split the train data to train (80%) and validation (20%) data sets\n",
        "split_idx = int(train_data.shape[0]/5)\n",
        "print(f'train_data.shape: {train_data.shape}, split_idx: {split_idx}')\n",
        "valid_set, train_set = train_data[:split_idx], train_data[split_idx:]\n",
        "print(f'valid_set.shape: {valid_set.shape}, train_set.shape: {train_set.shape}')\n",
        "#print(train_data)\n",
        "#print(test_m_data)\n",
        "#print(test_w_data)\n",
        "#print(valid_set)\n",
        "#print(train_set)\n",
        "\n"
      ],
      "metadata": {
        "id": "lZzIMXGt08hO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this code, include the image in your PDF submission\n",
        "plt.figure()\n",
        "plt.imshow(train_data[4,0,0,:,:,:]+ 0.5) # left shoe of first pair submitted by 5th student\n",
        "plt.figure()\n",
        "plt.imshow(train_data[4,0,1,:,:,:]+ 0.5) # right shoe of first pair submitted by 5th student\n",
        "plt.figure()\n",
        "plt.imshow(train_data[4,1,1,:,:,:]+ 0.5) # right shoe of second pair submitted by 5th student"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "k2HYqkkvYFFEYKNrSvH29r",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {}
        },
        "id": "02bKwE6c-LCD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (b)"
      ],
      "metadata": {
        "datalore": {
          "node_id": "M31szoZzg8PFQL7hPBychA",
          "type": "MD",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {}
        },
        "id": "ToMKNmGz-LCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here\n",
        "def generate_same_pair(data):\n",
        "  paired_data = []\n",
        "  for person in data:\n",
        "    for pair in person:\n",
        "      paired_data.append(cv2.vconcat(pair))\n",
        "  return np.array(paired_data)\n",
        "\n",
        "# Run this code, include the result with your PDF submission\n",
        "print(train_data.shape) # if this is [N, 3, 2, 224, 224, 3]\n",
        "print(generate_same_pair(train_data).shape) # should be [N*3, 448, 224, 3]\n",
        "plt.imshow(generate_same_pair(train_data)[0] + 0.5) # should show 2 shoes from the same pair"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "lZyhlAXsaXl7apZAHDfhTh",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {}
        },
        "id": "_9BuS23a-LCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models Creation\n"
      ],
      "metadata": {
        "datalore": {
          "node_id": "GnbqCRovBTXHQex3jFzpCx",
          "type": "MD",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {}
        },
        "id": "gvoFIsUk-LCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, n=4, kernel_size=5, stride=2, input_shape=(3, 448, 224)):\n",
        "      super(CNN, self).__init__()\n",
        "      # TODO: complete this method\n",
        "      padding_num = int((kernel_size-1)/2)\n",
        "      self.padding = (padding_num, padding_num)\n",
        "      self.C, self.H, self.W = input_shape\n",
        "\n",
        "      self.cnn1 = torch.nn.Conv2d(in_channels=self.C, out_channels=n, stride=stride, kernel_size=kernel_size, padding=self.padding)\n",
        "      self.cnn2 = torch.nn.Conv2d(in_channels=n, out_channels=2*n, stride=stride, kernel_size=kernel_size, padding=self.padding)\n",
        "      self.cnn3 = torch.nn.Conv2d(in_channels=2*n, out_channels=4*n, stride=stride, kernel_size=kernel_size, padding=self.padding)\n",
        "      self.cnn4 = torch.nn.Conv2d(in_channels=4*n, out_channels=8*n, stride=stride, kernel_size=kernel_size, padding=self.padding)\n",
        "      self.flatten = torch.nn.Flatten()\n",
        "      self.le_relu = torch.nn.LeakyReLU(0.1)\n",
        "      self.relu = torch.nn.ReLU()\n",
        "      self.logsoftmax = torch.nn.LogSoftmax(dim=1)\n",
        "\n",
        "      # after 4 Conv2D with stride=(2,2), the image shape is (h/(2**4),w/(2**4)), with 8*n channels\n",
        "      # thus, Linear input shape: (8*n)*((self.H*self.W)/(2**8))\n",
        "      fc1_inp = int((8*n)*((self.H*self.W)/(2**8)))\n",
        "      self.fc1 = torch.nn.Linear(in_features=fc1_inp, out_features=100)\n",
        "      self.fc2 = torch.nn.Linear(in_features=100, out_features=2)\n",
        "\n",
        "    # TODO: complete this class\n",
        "    def forward(self, x):\n",
        "      if DEBUG_NN:\n",
        "        print(f'in x.shape: {x.shape:}')\n",
        "      x = self.le_relu(self.cnn1(x))\n",
        "      x = self.le_relu(self.cnn2(x))\n",
        "      x = self.le_relu(self.cnn3(x))\n",
        "      x = self.le_relu(self.cnn4(x))\n",
        "      x = self.flatten(x)\n",
        "      y = self.relu(self.fc1(x))\n",
        "      y = self.fc2(y)\n",
        "      out = self.logsoftmax(y)\n",
        "      if DEBUG_NN:\n",
        "         print(f'log_softmax out.shape: {out.shape:}')\n",
        "      return out"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "jxGo1T39YtsSQ4xPAAccnQ",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {}
        },
        "id": "DBNoYHcS-LCM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1B59VE43X-6Dw3ag-9Ndn6vPEzbnFem8K\" width=\"400px\" />\n",
        "\n",
        "\n",
        "Complete the manipulation in the `forward()` method (by slicing and using\n",
        "the function `torch.cat`). The input to the first convolutional layer\n",
        "should have 6 channels instead of 3 (input shape $6 \\times 224 \\times 224$)."
      ],
      "metadata": {
        "datalore": {
          "node_id": "lQaEZOZX3xiJanLbc2dYzG",
          "type": "MD",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {}
        },
        "id": "TByFVD76-LCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to count number of parameters\n",
        "def get_n_params(model):\n",
        "    np=0\n",
        "    for p in list(model.parameters()):\n",
        "        np += p.nelement()\n",
        "    return np"
      ],
      "metadata": {
        "id": "EJ0kAEx2Oqrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(model, data, batch_size=50):\n",
        "    \"\"\"Compute the model accuracy on the data set. This function returns two\n",
        "    separate values: the model accuracy on the positive samples,\n",
        "    and the model accuracy on the negative samples.\n",
        "\n",
        "    Example Usage:\n",
        "\n",
        "    >>> model = CNN() # create untrained model\n",
        "    >>> pos_acc, neg_acc= get_accuracy(model, valid_data)\n",
        "    >>> false_positive = 1 - pos_acc\n",
        "    >>> false_negative = 1 - neg_acc\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    n = data.shape[0]\n",
        "\n",
        "    data_pos = generate_same_pair(data)      # should have shape [n * 3, 448, 224, 3]\n",
        "    data_neg = generate_different_pair(data) # should have shape [n * 3, 448, 224, 3]\n",
        "\n",
        "    pos_correct = 0\n",
        "    for i in range(0, len(data_pos), batch_size):\n",
        "        xs = torch.Tensor(data_pos[i:i+batch_size])\n",
        "        # reshape (our modification)\n",
        "        N, H, W, C = xs.shape\n",
        "        xs = xs.view(N,C,H,W)\n",
        "\n",
        "        zs = model(xs)\n",
        "        pred = zs.max(1, keepdim=True)[1] # get the index of the max logit\n",
        "        pred = pred.detach().numpy()\n",
        "        pos_correct += (pred == 1).sum()\n",
        "    \n",
        "    neg_correct = 0\n",
        "    for i in range(0, len(data_neg), batch_size):\n",
        "        xs = torch.Tensor(data_neg[i:i+batch_size])\n",
        "        # reshape (our modification)\n",
        "        N, H, W, C = xs.shape\n",
        "        xs = xs.view(N,C,H,W)\n",
        "\n",
        "        zs = model(xs)\n",
        "        pred = zs.max(1, keepdim=True)[1] # get the index of the max logit\n",
        "        pred = pred.detach().numpy()\n",
        "        neg_correct += (pred == 0).sum()\n",
        "\n",
        "    return pos_correct / (n * 3), neg_correct / (n * 3)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "Ai7RVnaLEu9ZcPGiQLAwdY",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {}
        },
        "id": "8MbJ_gLr-LCP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "datalore": {
          "node_id": "kbfdUiNBVZAKCP9VJi4h3R",
          "type": "MD",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {}
        },
        "id": "t17IDR4W-LCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "def train_model(model,\n",
        "                train_data=train_set,\n",
        "                validation_data=valid_set,\n",
        "                batch_size=100,\n",
        "                num_epochs=100,\n",
        "                learning_rate=0.001,\n",
        "                weight_decay=0,\n",
        "                checkpoint_path=None):\n",
        "  \n",
        "    # choice of loss function & optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(),\n",
        "                           lr=learning_rate,\n",
        "                           weight_decay=weight_decay)\n",
        "\n",
        "    iters, losses = [], []\n",
        "    epocs_vec, train_accs_pos, train_accs_neg, val_accs_pos, val_accs_neg  = [], [] ,[], [], []\n",
        "\n",
        "    # obtaining the positive and negative samples\n",
        "    pos_train = generate_same_pair(train_data)\n",
        "    neg_train = generate_different_pair(train_data)\n",
        "\n",
        "    # labels (one-hot representation)\n",
        "    pos_labels = torch.Tensor(np.array([np.eye(2)[1] for _ in range(batch_size // 2)]))  # one_hot(pos = 1) <=> [0,1]\n",
        "    neg_labels = torch.Tensor(np.array([np.eye(2)[0] for _ in range(batch_size // 2)]))  # one_hot(neg = 0) <=> [1,0]\n",
        "    labels = torch.cat([pos_labels, neg_labels], dim=0)\n",
        "\n",
        "    data_size = len(pos_train) + len(neg_train)\n",
        "\n",
        "    # main training loop\n",
        "    n = 0 # total number of iterations\n",
        "\n",
        "    for epoch in range(num_epochs):  # epochs\n",
        "        for i in range(0, data_size, batch_size):  # iterations in each epoch\n",
        "           \n",
        "            if (i + batch_size) > data_size:\n",
        "                break\n",
        "\n",
        "            # shuffle data (assume len(pos_train)=len(neg_train))\n",
        "            reindex = np.random.permutation(len(pos_train))\n",
        "            pos_train = pos_train[reindex]\n",
        "            reindex = np.random.permutation(len(pos_train))\n",
        "            neg_train = neg_train[reindex]\n",
        "\n",
        "            # create batch\n",
        "            pos_batch = pos_train[: batch_size // 2]\n",
        "            neg_batch = neg_train[: batch_size // 2]\n",
        "\n",
        "            # convert to tensors\n",
        "            pos_batch = torch.Tensor(pos_batch)\n",
        "            neg_batch = torch.Tensor(neg_batch)\n",
        "\n",
        "            # reshape\n",
        "            N, H, W, C = pos_batch.shape\n",
        "            pos_batch = pos_batch.view(N,C,H,W)\n",
        "            neg_batch = neg_batch.view(N,C,H,W)\n",
        "\n",
        "            # create input tensor\n",
        "            input_batch = torch.cat([pos_batch, neg_batch], dim=0)\n",
        "\n",
        "            # train\n",
        "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
        "            y = model(input_batch)        # compute prediction logit\n",
        "            loss = criterion(y, labels)   # compute the total loss\n",
        "            loss.backward()               # compute updates for each parameter\n",
        "            optimizer.step()              # make the updates for each parameter\n",
        "\n",
        "            # save the current training information\n",
        "            iters.append(n)\n",
        "            losses.append(float(loss)/batch_size)  # compute *average* loss\n",
        "\n",
        "            # increment the iteration number\n",
        "            n += 1\n",
        "\n",
        "\n",
        "        epocs_vec.append(epoch)\n",
        "        train_cost = float(loss.detach().numpy())\n",
        "\n",
        "        pos_acc_train, neg_acc_train = get_accuracy(model, train_data, batch_size=batch_size)\n",
        "        train_accs_pos.append(pos_acc_train)\n",
        "        train_accs_neg.append(neg_acc_train)\n",
        "\n",
        "        pos_acc_val, neg_acc_val = get_accuracy(model, valid_set, batch_size=batch_size)\n",
        "        val_accs_pos.append(pos_acc_val)\n",
        "        val_accs_neg.append(neg_acc_val)      \n",
        "    \n",
        "        print(\"Epoch %d, Iter %d. [Val Acc %.0f%% (pos: %.0f%%, neg: %.0f%%)] [Train Acc %.0f%% (pos: %.0f%%, neg: %.0f%%), Loss %f]\" % (\n",
        "              epoch, n, (pos_acc_val + neg_acc_val) * 50, pos_acc_val * 100, neg_acc_val * 100, (pos_acc_train + neg_acc_train) * 50, pos_acc_train * 100, neg_acc_train * 100, train_cost))\n",
        "\n",
        "        if (checkpoint_path is not None) and n > 0:\n",
        "            torch.save(model.state_dict(), checkpoint_path.format(epoch))\n",
        "\n",
        "    return iters, losses, epocs_vec, np.array(train_accs_pos), np.array(train_accs_neg), np.array(val_accs_pos), np.array(val_accs_neg)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "L2nI4GH7pTXOpwudqEk3bK",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {}
        },
        "id": "O-nwfXKQ-LCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curve(iters, losses, epocs_vec, train_accs_pos, train_accs_neg, val_accs_pos, val_accs_neg):\n",
        "    \"\"\"\n",
        "    Plot the learning curve.\n",
        "    \"\"\"\n",
        "    plt.title(\"Learning Curve: Loss per Iteration\")\n",
        "    plt.plot(iters, losses, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(15,5))\n",
        "    fig.suptitle(\"Learning Curve: Accuracy per Epoch\")\n",
        "\n",
        "    axs[0].plot(epocs_vec, train_accs_pos, label=\"Train\")\n",
        "    axs[0].plot(epocs_vec, val_accs_pos, label=\"Validation\")\n",
        "    axs[0].set_title('Positive Samples')\n",
        "    axs[0].set_xlabel(\"Epochs\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend()\n",
        "\n",
        "    axs[1].plot(epocs_vec, train_accs_neg, label=\"Train\")\n",
        "    axs[1].plot(epocs_vec, val_accs_neg, label=\"Validation\")\n",
        "    axs[1].set_title('Negative Samples')\n",
        "    axs[1].set_xlabel(\"Epochs\")\n",
        "    axs[1].set_ylabel(\"Accuracy\")\n",
        "    axs[1].legend()\n",
        "\n",
        "    axs[2].plot(epocs_vec, (train_accs_neg+train_accs_pos)/2, label=\"Train\")\n",
        "    axs[2].plot(epocs_vec, (val_accs_neg+val_accs_pos)/2, label=\"Validation\")\n",
        "    axs[2].set_title('Total Accuracy')\n",
        "    axs[2].set_xlabel(\"Epochs\")\n",
        "    axs[2].set_ylabel(\"Accuracy\")\n",
        "    axs[2].legend()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "RblRyNcBhuNmobyRC8AP2f",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {}
        },
        "id": "5iu1zQn3-LCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "toy_data_size = 6\n",
        "\n",
        "toy_train_data = train_set[:toy_data_size]\n",
        "toy_valid_data = valid_set[:toy_data_size]\n",
        "\n",
        "print(\"=== CNN ===\")\n",
        "cnn = CNN()\n",
        "cnn_learning_curve_info = train_model(model=cnn,\n",
        "                                  train_data=toy_train_data,\n",
        "                                  validation_data=toy_valid_data,\n",
        "                                  batch_size=6*toy_data_size,\n",
        "                                  num_epochs=20,\n",
        "                                  learning_rate=2e-3,\n",
        "                                  weight_decay=0,\n",
        "                                  checkpoint_path=None)\n",
        "\n",
        "plot_learning_curve(*cnn_learning_curve_info)\n",
        "print(f'len(cnn_learning_curve_info): {len(cnn_learning_curve_info)}')\n",
        "print(f'number of parememters cnn: {get_n_params(cnn)}')\n"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "L2nI4GH7pTXOpwudqEk3bK",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {}
        },
        "id": "rVt0cpuszCp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== CNNChannel ===\")\n",
        "\n",
        "cnnC = CNNChannel(n=4, kernel_size=5)\n",
        "cnnc_learning_curve_info = train_model(model=cnnC,\n",
        "                                  train_data=train_data,\n",
        "                                  validation_data=valid_set,\n",
        "                                  batch_size=80,\n",
        "                                  num_epochs=20,\n",
        "                                  learning_rate=1e-3,\n",
        "                                  weight_decay=0,\n",
        "                                  checkpoint_path = checkpoint_path)\n",
        "\n",
        "plot_learning_curve(*cnnc_learning_curve_info)"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "Vix0Jxd3A6mJ7zbqaQ72Wy",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {}
        },
        "id": "DzZeFuLe-LCS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "datalore": {
          "node_id": "3iFnqN0aCYs9F1IMbIm4da",
          "type": "MD",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {}
        },
        "id": "pgnhMgHR-LCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here. Make sure to include the test accuracy in your report\n",
        "\n",
        "# load CNNChannel model.\n",
        "# Model from last learning iteration had the best learning results.\n",
        "# We use model from iteration 20.\n",
        "model = CNNChannel()\n",
        "model.load_state_dict(torch.load(best_model_path))\n",
        "\n",
        "test_m_acc = get_accuracy(model=model, data=test_m_data, batch_size=100)\n",
        "test_m_acc = np.array(test_m_acc) * 100\n",
        "tot_acc_test_m = np.mean(test_m_acc)\n",
        "\n",
        "test_w_acc =get_accuracy(model=model, data=test_w_data, batch_size=100)\n",
        "test_w_acc = np.array(test_w_acc) * 100\n",
        "tot_acc_test_w = np.mean(test_w_acc)\n",
        "\n",
        "print('Man Shoes   [test_m]: Total accuracy = {:.2f}%, pos accuracy = {:.2f}%, neg accuracy = {:.2f}%'.format(tot_acc_test_m, test_m_acc[0], test_m_acc[1]))\n",
        "print('Woman Shoes [test_w]: Total accuracy = {:.2f}%, pos accuracy = {:.2f}%, neg accuracy = {:.2f}%'.format(tot_acc_test_w, test_w_acc[0], test_w_acc[1]))"
      ],
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "datalore": {
          "node_id": "uln1l5ZEsiwFS3uHpIJRAo",
          "type": "CODE",
          "hide_input_from_viewers": false,
          "hide_output_from_viewers": false,
          "report_properties": {}
        },
        "id": "yIbAdVy1-LCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction(model, input):\n",
        "    \"\"\" returns the predicion of a given model\n",
        "      inspired by the get_accuracy function\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    xs = torch.Tensor(input)\n",
        "    N, H, W, C = xs.shape\n",
        "    xs = xs.view(N,C,H,W)\n",
        "    zs = model(xs)\n",
        "    pred = zs.max(1, keepdim=True)[1] # get the index of the max logit\n",
        "    pred = pred.detach().numpy()[0,0]\n",
        "    return pred\n",
        "\n",
        "def get_correct_incorrect_pairs(data, gender):\n",
        "    same_pair = generate_same_pair(data)\n",
        "    found_true_positive = False\n",
        "    found_false_positive = False\n",
        "    for im in same_pair:\n",
        "        inp = np.expand_dims(im, 0)\n",
        "        pred = get_prediction(model, inp)\n",
        "        if pred == 1 and not found_true_positive:\n",
        "            found_true_positive = True\n",
        "            plt.figure()\n",
        "            plt.title(gender + ' test data CORRECT classification')\n",
        "            plt.imshow(im + 0.5)\n",
        "        if pred == 0 and not found_false_positive:\n",
        "            #found_false_positive = True\n",
        "            plt.figure()\n",
        "            plt.title(gender + ' test data INCORRECT classification')\n",
        "            plt.imshow(im + 0.5)\n",
        "        if found_true_positive and found_false_positive:\n",
        "            break"
      ],
      "metadata": {
        "id": "ewK-wX0If6fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As we can see from the negative results, our model sometimes makes wrong decisions and recognizes the shoes from the same pair as from different pairs.\n",
        "# We also see that pair number 4 contains different shoes - probably this is data set issue.\n",
        "get_correct_incorrect_pairs(test_m_data, 'Man')"
      ],
      "metadata": {
        "id": "AwV2nhlhf2pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automatic PDF Generation and store in GDrive"
      ],
      "metadata": {
        "id": "oTa5Ld8UWdZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install texlive texlive-xetex texlive-latex-extra pandoc > /dev/null 2>&1\n",
        "!pip install pypandoc > /dev/null 2>&1\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp 'drive/My Drive/Colab Notebooks/Assignment3_work.ipynb' ./\n",
        "\n",
        "!jupyter nbconvert --to PDF \"Assignment3_work.ipynb\" > /dev/null 2>&1\n",
        "!echo \"pdf file generated\"\n",
        "#!ls -la\n",
        "!cp './Assignment3_work.pdf' 'drive/My Drive/Colab Notebooks'"
      ],
      "metadata": {
        "id": "PAdX2kcL9OPF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "datalore": {
      "version": 1,
      "computation_mode": "JUPYTER",
      "package_manager": "pip",
      "base_environment": "default",
      "packages": []
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "oTa5Ld8UWdZm"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}