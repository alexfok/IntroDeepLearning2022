{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexfok/IntroDeepLearning2022/blob/main/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alexander Fok 308669944\n",
        "\n",
        "Avi Dvir 204423735\n",
        "\n",
        "Gal Cohen 204675805"
      ],
      "metadata": {
        "id": "L-g8kqS38eFL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx3i2Op-6X5n"
      },
      "source": [
        "# Assignment 2: Word Prediction\n",
        "\n",
        "**Deadline**: Sunday, December 11th, by 8pm.\n",
        "\n",
        "**Submission**: Submit a PDF export of the completed notebook as well as the ipynb file. \n",
        "\n",
        " \n",
        "\n",
        "In this assignment, we will make a neural network that can predict the next word\n",
        "in a sentence given the previous three.  \n",
        "In doing this prediction task, our neural networks will learn about *words* and about\n",
        "how to represent words. We'll explore the *vector representations* of words that our\n",
        "model produces, and analyze these representations.\n",
        "\n",
        "You may modify the starter code as you see fit, including changing the signatures of functions and adding/removing helper functions. However, please make sure that you properly explain what you are doing and why."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zdEvcdO6X5s"
      },
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQYtUQTH6X5t"
      },
      "source": [
        "## Question 1. Data (18%)\n",
        "\n",
        "With any machine learning problem, the first thing that we would want to do\n",
        "is to get an intuitive understanding of what our data looks like. Download the file\n",
        "`raw_sentences.txt` from the course page on Moodle and upload it to Google Drive.\n",
        "Then, mount Google Drive from your Google Colab notebook:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eWXHhCe6X5t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8217ff5e-ba7d-4118-d4b2-0fce1e9a775b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hteg6bwv6X5t"
      },
      "source": [
        "Find the path to `raw_sentences.txt`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALMsGfFi6X5u"
      },
      "source": [
        "file_path = '/content/gdrive/My Drive/IntroDeepLearning2022Data/raw_sentences.txt'"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD5uXTle6X5u"
      },
      "source": [
        "The following code reads the sentences in our file, split each sentence into\n",
        "its individual words, and stores the sentences (list of words) in the\n",
        "variable `sentences`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75NXJO_T6X5v"
      },
      "source": [
        "sentences = []\n",
        "for line in open(file_path):\n",
        "    words = line.split()\n",
        "    sentence = [word.lower() for word in words]\n",
        "    sentences.append(sentence)"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbP0-e_U6X5v"
      },
      "source": [
        "There are 97,162 sentences in total, and \n",
        "these sentences are composed of 250 distinct words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLUp8rZT6X5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f09b391-4a7b-4cf1-ad0d-83997940320a"
      },
      "source": [
        "vocab = set([w for s in sentences for w in s])\n",
        "print(len(sentences)) # 97162\n",
        "print(len(vocab)) # 250"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97162\n",
            "250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB77tJrU6X5v"
      },
      "source": [
        "We'll separate our data into training, validation, and test.\n",
        "We'll use `10,000 sentences for test, 10,000 for validation, and\n",
        "the rest for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJQRB6RJ6X5v"
      },
      "source": [
        "test, valid, train = sentences[:10000], sentences[10000:20000], sentences[20000:]"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUj7fsi06X5v"
      },
      "source": [
        "### Part (a) -- 3%\n",
        "\n",
        "**Display** 10 sentences in the training set.\n",
        "**Explain** how punctuations are treated in our word representation, and how words\n",
        "with apostrophes are represented."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90AmLcpF6X5w"
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swyMJHYN-Taa"
      },
      "source": [
        "**Write your answers here:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2erKpOJ6X5w"
      },
      "source": [
        "### Part (b) -- 4%\n",
        "\n",
        "**Print** the 10 most common words in the vocabulary and how often does each of these\n",
        "words appear in the training sentences. Express the second quantity as a percentage\n",
        "(i.e. number of occurences of the  word / total number of words in the training set).\n",
        "\n",
        "These are useful quantities to compute, because one of the first things a machine learning model will learn is to predict the **most common** class. Getting a sense of the\n",
        "distribution of our data will help you understand our model's behaviour.\n",
        "\n",
        "You can use Python's `collections.Counter` class if you would like to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqSZO_a36X5w"
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4CHlVRI6X5w"
      },
      "source": [
        "### Part (c) -- 11%\n",
        "\n",
        "Our neural network will take as input three words and predict the next one. Therefore, we need our data set to be comprised of seuqnces of four consecutive words in a sentence, referred to as *4grams*. \n",
        "\n",
        "**Complete** the helper functions `convert_words_to_indices` and\n",
        "`generate_4grams`, so that the function `process_data` will take a \n",
        "list of sentences (i.e. list of list of words), and generate an \n",
        "$N \\times 4$ numpy matrix containing indices of 4 words that appear\n",
        "next to each other, where $N$ is the number of 4grams (sequences of 4 words appearing one after the other) that can be found in the complete list of sentences. Examples of how these functions should operate are detailed in the code below. \n",
        "\n",
        "You can use the defined `vocab`, `vocab_itos`,\n",
        "and `vocab_stoi` in your code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUZsxdHk6X5w"
      },
      "source": [
        "# A list of all the words in the data set. We will assign a unique \n",
        "# identifier for each of these words.\n",
        "vocab = sorted(list(set([w for s in train for w in s])))\n",
        "# A mapping of index => word (string)\n",
        "vocab_itos = dict(enumerate(vocab))\n",
        "# A mapping of word => its index\n",
        "vocab_stoi = {word:index for index, word in vocab_itos.items()}\n",
        "\n",
        "def convert_words_to_indices(sents):\n",
        "    \"\"\"\n",
        "    This function takes a list of sentences (list of list of words)\n",
        "    and returns a new list with the same structure, but where each word\n",
        "    is replaced by its index in `vocab_stoi`.\n",
        "\n",
        "    Example:\n",
        "    >>> convert_words_to_indices([['one', 'in', 'five', 'are', 'over', 'here'], ['other', 'one', 'since', 'yesterday'], ['you']])\n",
        "    [[148, 98, 70, 23, 154, 89], [151, 148, 181, 246], [248]]\n",
        "    \"\"\"\n",
        "\n",
        "    #Write your code here\n",
        "    return [[vocab_stoi[word] for word in sent] for sent in sents]\n",
        "\n",
        "def generate_4grams(seqs):\n",
        "    \"\"\"\n",
        "    This function takes a list of sentences (list of lists) and returns\n",
        "    a new list containing the 4-grams (four consequentively occuring words)\n",
        "    that appear in the sentences. Note that a unique 4-gram can appear multiple\n",
        "    times, one per each time that the 4-gram appears in the data parameter `seqs`.\n",
        "\n",
        "    Example:\n",
        "\n",
        "    >>> generate_4grams([[148, 98, 70, 23, 154, 89], [151, 148, 181, 246], [248]])\n",
        "    [[148, 98, 70, 23], [98, 70, 23, 154], [70, 23, 154, 89], [151, 148, 181, 246]]\n",
        "    >>> generate_4grams([[1, 1, 1, 1, 1]])\n",
        "    [[1, 1, 1, 1], [1, 1, 1, 1]]\n",
        "    \"\"\"\n",
        "\n",
        "    # Write your code here\n",
        "    indices = []\n",
        "    for sent in seqs:\n",
        "      sent_idx = 0\n",
        "      while sent_idx + 4 <= len(sent):\n",
        "        t_4gram = sent[sent_idx:sent_idx + 4]\n",
        "        indices.append(t_4gram)\n",
        "        sent_idx += 1\n",
        "    return indices;\n",
        "#    return [[vocab_stoi[word] for word in sent] for sent in seqs]\n",
        "\n",
        "def process_data(sents):\n",
        "    \"\"\"\n",
        "    This function takes a list of sentences (list of lists), and generates an\n",
        "    numpy matrix with shape [N, 4] containing indices of words in 4-grams.\n",
        "    \"\"\"\n",
        "    indices = convert_words_to_indices(sents)\n",
        "    fourgrams = generate_4grams(indices)\n",
        "    return np.array(fourgrams)\n",
        "\n",
        "# We can now generate our data which will be used to train and test the network\n",
        "train4grams = process_data(train)\n",
        "valid4grams = process_data(valid)\n",
        "test4grams = process_data(test)\n",
        "#print(convert_words_to_indices([['one', 'in', 'five', 'are', 'over', 'here'], ['other', 'one', 'since', 'yesterday'], ['you']]))\n",
        "#print(generate_4grams([[148, 98, 70, 23, 154, 89], [151, 148, 181, 246], [248]]))\n",
        "#print(generate_4grams([[1, 1, 1, 1, 1]]))\n",
        "#print(test)\n",
        "#print(test4grams)"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Rv-6sNm6X5x"
      },
      "source": [
        "## Question 2. A Multi-Layer Perceptron (44%)\n",
        "\n",
        "In this section, we will build a two-layer multi-layer perceptron. \n",
        "Our model will look like this:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=15uMLB-YsMHSOr0EQfTRhWd4o9enIOjUe\">\n",
        "\n",
        "Since the sentences in the data are comprised of $250$ distinct words, our task boils down to claissfication where the label space $\\mathcal{S}$ is of cardinality $|\\mathcal{S}|=250$ while our input, which is comprised of a combination of three words, is treated as a vector of size $750\\times 1$ (i.e., the concatanation of three one-hot $250\\times 1$ vectors).\n",
        "\n",
        "The following function `get_batch` will take as input the whole dataset and output a single batch for the training. The output size of the batch is explained below.\n",
        "\n",
        "**Implement** yourself a function `make_onehot` which takes the data in index notation and output it in a onehot notation.\n",
        "\n",
        "Start by reviewing the helper function, which is given to you:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsqTLOoJ6X5x"
      },
      "source": [
        "def make_onehot(data):\n",
        "    \"\"\"\n",
        "    Convert one batch of data in the index notation into its corresponding onehot\n",
        "    notation. Remember, the function should work for both xt and st. \n",
        "     \n",
        "    input - vector with shape D (1D or 2D)\n",
        "    output - vector with shape (D,250)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Write your code here\n",
        "    n_class = 250\n",
        "    flat_data = data.reshape(-1)\n",
        "\n",
        "    data_encode_idx = 0\n",
        "    data_encode = np.zeros((flat_data.shape[0], n_class))\n",
        "    for idx, val in enumerate(data):\n",
        "        data_encode[idx, val] = 1.0\n",
        "   \n",
        "    return data_encode\n",
        "\n",
        "def get_batch(data, range_min, range_max, onehot=True):\n",
        "    \"\"\"\n",
        "    Convert one batch of data in the form of 4-grams into input and output\n",
        "    data and return the training data (xt, st) where:\n",
        "     - `xt` is an numpy array of one-hot vectors of shape [batch_size, 3, 250]\n",
        "     - `st` is either\n",
        "            - a numpy array of shape [batch_size, 250] if onehot is True,\n",
        "            - a numpy array of shape [batch_size] containing indicies otherwise\n",
        "\n",
        "    Preconditions:\n",
        "     - `data` is a numpy array of shape [N, 4] produced by a call\n",
        "        to `process_data`\n",
        "     - range_max > range_min\n",
        "    \"\"\"\n",
        "    xt = data[range_min:range_max, :3]\n",
        "    xt = make_onehot(xt)\n",
        "    xt = xt.reshape(-1, 3 , 250)\n",
        "\n",
        "    st = data[range_min:range_max, 3]\n",
        "    if onehot:\n",
        "        st = make_onehot(st).reshape(-1, 250)\n",
        "    return xt, st\n"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test get_batch\n",
        "test1 = sentences[:3]\n",
        "#print(test1)\n",
        "data = process_data(test1)\n",
        "print(data)\n",
        "range_min = 0\n",
        "range_max = 4\n",
        "xt, st = get_batch(data, range_min, range_max, onehot=True)\n",
        "#xt, st = get_batch(data, range_min, range_max, onehot=False)\n",
        "# test make_onehot\n",
        "print(f'xt.shape {xt.shape}')\n",
        "xt_flat = xt.reshape(-1, 250)\n",
        "print(f'xt_flat.shape {xt_flat.shape}')\n",
        "for idx, val in enumerate(xt_flat):\n",
        "    for idx2, val_1 in enumerate(val):\n",
        "      if val_1 > 0:\n",
        "        print(f'idx: {idx2}, ')\n",
        "print(f'st.shape {st.shape}')\n",
        "for idx, val in enumerate(st):\n",
        "    for idx2, val_1 in enumerate(val):\n",
        "      if val_1 > 0:\n",
        "        print(f'idx: {idx2}, ')\n"
      ],
      "metadata": {
        "id": "DALldy-qoWsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvLuZpH-6X52"
      },
      "source": [
        "### Part (a) -- 8%\n",
        "\n",
        "We build the model in PyTorch. Since PyTorch uses automatic\n",
        "differentiation, we only need to write the *forward pass* of our\n",
        "model. \n",
        "\n",
        "**Complete** the `forward` function below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMzWMUB16X52"
      },
      "source": [
        "class PyTorchMLP(nn.Module):\n",
        "    def __init__(self, num_hidden=400):\n",
        "        super(PyTorchMLP, self).__init__()\n",
        "        self.layer1 = nn.Linear(750, num_hidden)\n",
        "        self.layer2 = nn.Linear(num_hidden, 250)\n",
        "        self.num_hidden = num_hidden\n",
        "#        self.soft_max = nn.Softmax(dim=1)\n",
        "    def forward(self, inp):\n",
        "        inp = inp.reshape([-1, 750])\n",
        "        # TODO: complete this function \n",
        "        # Note that we will be using the nn.CrossEntropyLoss(), which computes the softmax operation internally, as loss criterion\n",
        "        x = self.layer1(inp)\n",
        "        x = self.layer2(x)\n",
        "#        y = self.soft_max(x)\n",
        "        return x\n",
        "\n"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "114NF7If6X52"
      },
      "source": [
        "### Part (b) -- 10%\n",
        "\n",
        "We next  train the PyTorch model using the Adam optimizer and the cross entropy loss.\n",
        "\n",
        "**Complete** the function `run_pytorch_gradient_descent`, and use it to train your PyTorch MLP model.\n",
        "\n",
        "**Obtain** a training accuracy of at least 35% while changing only the hyperparameters of the train function.\n",
        "\n",
        "Plot the learning curve using the `plot_learning_curve` function provided\n",
        "to you, and include your plot in your PDF submission."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY70vUCZ6X52"
      },
      "source": [
        "def estimate_accuracy_torch(model, data, batch_size=5000, max_N=100000):\n",
        "    \"\"\"\n",
        "    Estimate the accuracy of the model on the data. To reduce\n",
        "    computation time, use at most `max_N` elements of `data` to\n",
        "    produce the estimate.\n",
        "    \"\"\"\n",
        "    correct = 0\n",
        "    N = 0\n",
        "    for i in range(0, data.shape[0], batch_size):\n",
        "        # get a batch of data\n",
        "        xt, st = get_batch(data, i, i + batch_size, onehot=False)\n",
        "        \n",
        "        # forward pass prediction\n",
        "        y = model(torch.Tensor(xt))\n",
        "        y = y.detach().numpy() # convert the PyTorch tensor => numpy array\n",
        "        pred = np.argmax(y, axis=1)\n",
        "        correct += np.sum(pred == st)\n",
        "        N += st.shape[0]\n",
        "\n",
        "        if N > max_N:\n",
        "            break\n",
        "    return correct / N\n",
        "\n",
        "def run_pytorch_gradient_descent(model,\n",
        "                                 train_data=train4grams,\n",
        "                                 validation_data=valid4grams,\n",
        "                                 batch_size=100,\n",
        "                                 learning_rate=0.001,\n",
        "                                 weight_decay=0,\n",
        "                                 max_iters=1000,\n",
        "                                 checkpoint_path=None):\n",
        "    \"\"\"\n",
        "    Train the PyTorch model on the dataset `train_data`, reporting\n",
        "    the validation accuracy on `validation_data`, for `max_iters`\n",
        "    iteration.\n",
        "\n",
        "    If you want to **checkpoint** your model weights (i.e. save the\n",
        "    model weights to Google Drive), then the parameter\n",
        "    `checkpoint_path` should be a string path with `{}` to be replaced\n",
        "    by the iteration count:\n",
        "\n",
        "    For example, calling \n",
        "\n",
        "    >>> run_pytorch_gradient_descent(model, ...,\n",
        "            checkpoint_path = '/content/gdrive/My Drive/Intro_to_Deep_Learning/mlp/ckpt-{}.pk')\n",
        "\n",
        "    will save the model parameters in Google Drive every 500 iterations.\n",
        "    You will have to make sure that the path exists (i.e. you'll need to create\n",
        "    the folder Intro_to_Deep_Learning, mlp, etc...). Your Google Drive will be populated with files:\n",
        "\n",
        "    - /content/gdrive/My Drive/Intro_to_Deep_Learning/mlp/ckpt-500.pk\n",
        "    - /content/gdrive/My Drive/Intro_to_Deep_Learning/mlp/ckpt-1000.pk\n",
        "    - ...\n",
        "\n",
        "    To load the weights at a later time, you can run:\n",
        "\n",
        "    >>> model.load_state_dict(torch.load('/content/gdrive/My Drive/Intro_to_Deep_Learning/mlp/ckpt-500.pk'))\n",
        "\n",
        "    This function returns the training loss, and the training/validation accuracy,\n",
        "    which we can use to plot the learning curve.\n",
        "    \"\"\"\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(),\n",
        "                           lr=learning_rate,\n",
        "                           weight_decay=weight_decay)\n",
        "\n",
        "    iters, losses = [], []\n",
        "    iters_sub, train_accs, val_accs  = [], [] ,[]\n",
        "\n",
        "    n = 0 # the number of iterations\n",
        "    while True:\n",
        "        for i in range(0, train_data.shape[0], batch_size):\n",
        "            if (i + batch_size) > train_data.shape[0]:\n",
        "                break\n",
        "\n",
        "            # get the input and targets of a minibatch\n",
        "            xt, st = get_batch(train_data, i, i + batch_size, onehot=False)\n",
        "\n",
        "            # convert from numpy arrays to PyTorch tensors\n",
        "            xt = torch.Tensor(xt)\n",
        "            st = torch.Tensor(st).long()\n",
        "\n",
        "            # zs = ...                 # compute prediction logit\n",
        "            # loss =                   # compute the total loss\n",
        "            # ...                      # compute updates for each parameter\n",
        "            # ...                      # make the updates for each parameter\n",
        "            # ...                      # a clean up step for PyTorch\n",
        "            # zero the gradients before running\n",
        "            # the backward pass.\n",
        "            optimizer.zero_grad()\n",
        "            output = model(xt)\n",
        "#            print(f'output.shape {output.shape}, st.shape {st.shape}')\n",
        "            loss = criterion(output, st)\n",
        "            # Backward pass to compute the gradient\n",
        "            # of loss w.r.t our learnable params. \n",
        "            loss.backward()\n",
        "            \n",
        "            # Update params\n",
        "            optimizer.step()\n",
        "\n",
        "            # save the current training information\n",
        "            iters.append(n)\n",
        "            losses.append(float(loss)/batch_size)  # compute *average* loss\n",
        "\n",
        "            if n % 500 == 0:\n",
        "                iters_sub.append(n)\n",
        "                train_cost = float(loss.detach().numpy())\n",
        "                print(f'estimate_accuracy_torch')\n",
        "                train_acc = estimate_accuracy_torch(model, train_data)\n",
        "                train_accs.append(train_acc)\n",
        "                val_acc = estimate_accuracy_torch(model, validation_data)\n",
        "                val_accs.append(val_acc)\n",
        "                print(\"Iter %d. [Val Acc %.0f%%] [Train Acc %.0f%%, Loss %f]\" % (\n",
        "                      n, val_acc * 100, train_acc * 100, train_cost))\n",
        "\n",
        "                if (checkpoint_path is not None) and n > 0:\n",
        "                    torch.save(model.state_dict(), checkpoint_path.format(n))\n",
        "\n",
        "            # increment the iteration number\n",
        "            n += 1\n",
        "\n",
        "            if n > max_iters:\n",
        "                return iters, losses, iters_sub, train_accs, val_accs\n",
        "\n",
        "\n",
        "def plot_learning_curve(iters, losses, iters_sub, train_accs, val_accs):\n",
        "    \"\"\"\n",
        "    Plot the learning curve.\n",
        "    \"\"\"\n",
        "    plt.title(\"Learning Curve: Loss per Iteration\")\n",
        "    plt.plot(iters, losses, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Learning Curve: Accuracy per Iteration\")\n",
        "    plt.plot(iters_sub, train_accs, label=\"Train\")\n",
        "    plt.plot(iters_sub, val_accs, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXBq-1F86X52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "outputId": "35dfb379-8d98-4ed2-f26e-0a720eed0ef2"
      },
      "source": [
        "pytorch_mlp = PyTorchMLP(800)\n",
        "# learning_curve_info = run_pytorch_gradient_descent(pytorch_mlp, ...)\n",
        "checkpoint_path = '/content/gdrive/My Drive/IntroDeepLearning2022Data/mlp/ckpt-{}.pk'\n",
        "\n",
        "iters, losses, iters_sub, train_accs, val_accs = run_pytorch_gradient_descent(pytorch_mlp,\n",
        "                                 train_data=train4grams,\n",
        "                                 validation_data=valid4grams,\n",
        "                                 batch_size=300,\n",
        "                                 learning_rate=0.001,\n",
        "                                 weight_decay=0,\n",
        "                                 max_iters=3000,\n",
        "                                 checkpoint_path=checkpoint_path)\n",
        "\n",
        "plot_learning_curve(iters, losses, iters_sub, train_accs, val_accs)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "estimate_accuracy_torch\n",
            "Iter 0. [Val Acc 4%] [Train Acc 4%, Loss 5.519290]\n",
            "estimate_accuracy_torch\n",
            "Iter 500. [Val Acc 17%] [Train Acc 17%, Loss 4.432355]\n",
            "estimate_accuracy_torch\n",
            "Iter 1000. [Val Acc 17%] [Train Acc 17%, Loss 4.396914]\n",
            "estimate_accuracy_torch\n",
            "Iter 1500. [Val Acc 17%] [Train Acc 17%, Loss 4.416288]\n",
            "estimate_accuracy_torch\n",
            "Iter 2000. [Val Acc 17%] [Train Acc 17%, Loss 4.342834]\n",
            "estimate_accuracy_torch\n",
            "Iter 2500. [Val Acc 17%] [Train Acc 17%, Loss 4.403403]\n",
            "estimate_accuracy_torch\n",
            "Iter 3000. [Val Acc 17%] [Train Acc 17%, Loss 4.369577]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxU9Znv8c+3G+hmk7VBpUEaQTYXlgY0bhiNUZPImGACmbmBJBMTc51s10lMJnGIGe9k8U4ymfgyMdfEJRrcMgZzSYwbuKF2g2zNIi2yNCI0+9r09tw/zmlSFFXd1U1Xn6rq5/161avP8jvnPL861fXUOb9zfkdmhnPOORcvL+oAnHPOZSZPEM455xLyBOGccy4hTxDOOecS8gThnHMuIU8QzjnnEvIE4ZKSdKmk9VHH4Vx7knRI0oio48gGniAylKRNkq6KMgYze9nMRqdr/ZI+LOklSQclVUtaLOn6dG3vVEmaLskkfSvqWLJV7Oda0lxJr6R5e4sk/WPsNDPrZWYb07ndXOEJohOTlB/htmcCjwMPAsXAYOB24GNtWJckdcRneQ6wB/hMB2zruA6sX7vpiJgldUnn+h1gZv7KwBewCbgqwfQ84DbgHWA38BjQP2b+48D7wH7gJWB8zLz7gXuAhcBh4KpwO7cCK8NlHgUKw/LTgaq4mBKWDed/E9gOvAf8I2DAyAR1ELAF+Odm6j8P+F3M+PBwfV3C8UXAncCrwFHgW0B53Dq+DiwIhwuAu8Lt7gB+CXRvxf7oCRwEZgG1QGnc/C8Aa8Mya4BJ4fShwB+A6nB//aKN9RsJfDZmGxuBL8bFMANYDhwIPx/XADcCS+PKfQP4Y5J6LgL+HXgzXM8f4z5fFwKvAfuAFcD0uGVPiDnZ5xoYC9QADcAhYF9L+4nw8xju6/eBh4B+wJ/C93dvOFwclr8zXH9NuI2m9/745xLoQ/AjpRrYDHwXyAvnzQVeCePZC7wLXBv1d0NHviIPwF9JdkzyBPFV4HWCX90FwK+A38fM/xzQO5z3M2B5zLz7Cb7YLyZINIXhdt4EzgT6h19AXwrLT+fkBJGs7DXhP+14oAfwO5IniDHhvJJm6j+Plr9At4Tb6xL+ox8ERsUsUwbMCod/CiwI4+4NPA38e0zZfcAlzcTzPwiSX3647H/FzLsR2AZMIUh+I4GzwrIrwm33DN/vS9pYv67AR4Czw21cDhzhb4loarhvPxTu2yHh+1xAcNQzNmZbbwGfSFLPRWFdzg1jfrIpznCdu4Hrwm18KBwvShZzc59rwi/guPlJ9xPB57Ee+FFYr+7AAOATBJ+53gQ/kJ6Kq88/xm0jNkE8SJAEe4f74G3g8zHx1REk/3zgZoIfP4r6+6HDvoeiDsBfSXZM8gSxFrgyZvyM8EPcJUHZvuE/Q59w/H7gwQTb+YeY8R8DvwyHp3NygkhW9jec+IU7kuQJ4uJwXmH8vJgy82j5C/SOuGV+B9weDo8iSBg9CL5QDwNnx5S9CHi3FfvjOeBn4fBsgl+cXcPxZ4CvJljmorBcon3T6volWMdTTdsl+KHw0yTl7gHuDIfHE/waLkhSdhHww5jxcQRHTPkEv9wfiiv/DDCnFTFvIkmCaGk/hZ/H2hY+NxOAvXH1SZggwjrVAuNi5n0RWBQTX2XMvB7hsqen+rnJ9ldWndd0QPDL9L8l7ZO0jyBhNACDJeVL+qGkdyQdIPhnBBgYs/zWBOt8P2b4CNCrme0nK3tm3LoTbafJ7vDvGc2USUX8Nh4h+PIG+DTBL8kjQBHBP/fSmPftL+H0FkkaClwBPBxO+iPB0cBHwvGhBKd04g0FNptZfWrVOckJ9ZN0raTXJe0J63Adf9u3yWIAeAD4tCQRHAk9ZmbHUtzuZoKjl4EEn70bm97DMIZLOHE/NrffW5LKfqo2s5qmEUk9JP1K0ubwM/8S0DfF9rWBYd02x0zbTHCk1OT45z38LEHz/x85xRNE9tlKcB60b8yr0My2EXwpziA4x9uH4FcpBL/Mmlia4tpOcNqrydBmyq4nqMcnmilzmODLosnpCcrE1+VZoEjSBIJE8Ug4fRfBOfHxMe9ZHzNL9R/9fxD8rzwt6X2C8/+FBI3WhHU5O8FyW4FhSRpTW1U/SQUEp3vuAgabWV+CtqSmfZssBszsdYJfypcSfEYeSlQuRuy+G0ZwhLor3MZDcZ+9nmb2w0QxpyC+bCr7KX6Z/wWMBqaZ2WnAZeF0JSkfv706gsTXZBjBKTaHJ4hM11VSYcyrC0Gj3Z2SzgKQVCRpRli+N3CM4Bd6D+B/d2CsjwGflTRWUg/ge8kKWnC8/g3ge5I+K+k0SXmSLpF0b1hsOXCZpGGS+gDfbikAM6sjOAf9E4Jz2M+G0xuBXwM/lTQIQNIQSR9OsW5zgO8TnL5oen0CuE7SAOD/ArdKmhxevTMy3D9vEiTOH0rqGe7Di9tYv24E592rgXpJ1wJXx8y/j+D9vzJ8L4dIGhMz/0HgF0CdmbV0aek/SBoX7sc7gCfMrIHgFN7HwsuT88P6TJdU3PzqktoBFEvqBm3eT70Jkso+Sf2Bf02wjYT3PIR1eozg/6l3uM++EdbT4Qki0y0k+PA3veYB/0nQiPdXSQcJGqynheUfJDhE3kZwJc3rHRWomf0Z+DnwIlAZs+2EpzLM7AngUwSN6u8R/CP/G8HpG8zsWYKrpFYCSwmuTknFIwRHUI/Hndr5VlNc4amI5wh+eQLHb566NH5lki4k+IV5t5m9H/NaEK5vtpk9TnDFzCME7R5PEVz500Bw2e5IgsbbqrDOra6fmR0EvkLwhbaX4EhgQcz8NwmucvopQWP1Yk78ZfwQQcNzKl9+DxG0V71PcKT0lXAbWwmOUL9DkKi2Av9M279HXgAqgPcl7QqnNbufEvgZQWP1LoLP3F/i5v8nMFPSXkk/T7D8PxEczW0kuGLpEYL2NEfYGu9ce5M0FlhN0Bja1nPwrp1I6g7sJLjqaUMz5RYRNJ7/346KzWUuP4Jw7UbSDZIKJPUjuBTxaU8OGeNmoKy55OBcPL8T0bWnLxKcmmggOMXx5UijcUDQvQVBo+3fRRyKyzJ+isk551xC6e4r5RpJ6yVVSrotwfzLJC2TVB/2zRM778eSKiStlfTz8Bpu55xzHSRtp5jCG1XuJrgdvwook7TAzNbEFNtCcLfirXHLfoDgbtvzw0mvEHQtsCjZ9gYOHGjDhw9vp+idc65zWLp06S4zS3jTaDrbIKYS3Ka+EUDSfIJL5I4nCDPbFM5rjFvWCC6v60Zw7rQrwWWQSQ0fPpzy8vL2it055zoFSZuTzUvnKaYhnHjbfRUn3sKelJktIbiefnv4esbM1saXk3STpHJJ5dXV1e0QsnPOuSYZeZmrpJEE3QEXEySVDya6icnM7jWzUjMrLSpKqVsd55xzKUpngtjGiX26FJN6Hyc3AK+b2SEzOwT8maBXR+eccx0knQmiDBglqSTsa2UWMV0DtGALcLmkLpK6EjRQn3SKyTnnXPqkLUGEd9DeQtBf/FqCLoYrJN2h8LnDkqZIqiJ44MqvJFWEiz9B0HXxKoIHrqwws6fTFatzzrmT5cyNcqWlpeZXMTnnXOtIWmpmpYnmZWQjtXPOueh5X0w5ZP/ROh5+YzO19fG3lTSvtQeRbTrmzJEjVZdEXEcHibo9SNQXguJKJi6TwnpS6Ggh2fabpiumXFNcscs0bUMx0xUz74RpMWUTrTN2elMcxCyvRMvHlI2vS/+e3bh0VPtfyekJIoc8Xr6VH/9lfdRhJOWdpeQmz/3RmzC0rycI17wllTv5SL+t/OKT41u9rHd1FaUk733SfdLMvmrtMs3u97Ysk1iits74SYnyjKVwvJooQcUvlyyJmRHWxwBh4aspHiP46X68nAlT07LhPBSsSCcvHyxz4nqC6bHL/y0Oa1p5OGxhbE3DJ5SN2U63rgUtvk9t4QkiR9Q3NDJo09P8u34RPKLeuQyS8JRTh0eRw4aUwheeb/fVeoLIEau27Wda4zKO9RhAwaz7ow7HpSrp+ZnmfvImXVn7bKPZWTl2Pun4e2PhsMVMtzbM58T5p7QuS7KuBHH3Sk9PEp4gcsRrlbu4MW8NlFwBJZdFHY5zLgd4gsgRW95+i0HaB6OuiDoU51yO8PsgcsCx+gZ6vfdqMOJHD865duIJIgcs37KPqbaaoz2GQP+SqMNxzuUITxA54PV3dnJh3hryz54edSjOuRzibRA5YPu6N+mjI97+4JxrV34EkeWO1jbQf+eSYKTkpGcqOedcm3mCyHLlm/dwIas5fNpI6H161OE453KIJ4gs98aG95mSt55uo6ZHHYpzLsd4G0SW27P+VbqrFkZ6+4Nzrn35EUQWO1hTx+A9b9JIHgy/JOpwnHM5xhNEFivbtIeLtJojA8ZD975Rh+OcyzGeILJY2fqtTFQlhed8MOpQnHM5KK0JQtI1ktZLqpR0W4L5l0laJqle0sy4ecMk/VXSWklrJA1PZ6zZ6NCGV+iqBrqcfXnUoTjnclDaEoSkfOBu4FpgHDBb0ri4YluAucAjCVbxIPATMxsLTAV2pivWbLT3cC1D971Jg7rAsIuiDsc5l4PSeRXTVKDSzDYCSJoPzADWNBUws03hvBMeohwmki5m9mxY7lAa48xKb7y7m4vyKjgyaBK9u/WIOhznXA5K5ymmIcDWmPGqcFoqzgH2SfqDpLck/SQ8InGht9a/y3htpvvoK6MOxTmXozK1kboLcClwKzAFGEFwKuoEkm6SVC6pvLq6umMjjNixysXkybz9wTmXNulMENuAoTHjxeG0VFQBy81so5nVA08Bk+ILmdm9ZlZqZqVFRel55F4m2nmwhhEHl1KX3x2GTI46HOdcjkpngigDRkkqkdQNmAUsaMWyfSU1fet/kJi2i85uyTu7+UBeBUfPmApdukUdjnMuR6UtQYS//G8BngHWAo+ZWYWkOyRdDyBpiqQq4EbgV5IqwmUbCE4vPS9pFSDg1+mKNdtUrFvHyLz36DXmqqhDcc7lsLT2xWRmC4GFcdNujxkuIzj1lGjZZ4Hz0xlftmp89yUA8kb440Wdc+mTqY3ULomqvUcYfXgZNV37wOmeP51z6eMJIsssqdzFRflrqB16MeT57nPOpY9/w2SZDetXUqxd9Brt/S8559LLE0QWMTPyN4XtD2dPjzYY51zO8wSRRTbtPsL4Yys4UjAIBoyMOhznXI7zBJFFXqvcyUV5FTQMvxSkqMNxzuU4f+RoFtm8tpwBOoiN8fYH51z6+RFEljAzCra8DIBKvP8l51z6eYLIEm/vOMQF9Ss52GMY9B3a8gLOOXeKPEFkidc3vM+0vHVohB89OOc6hrdBZIn31i6ht46Ctz845zqIH0FkgYZGo9d7rwYjJd7/knOuY3iCyAJrtx9gUsMq9p82GnoOjDoc51wn4QkiC7zxdhWleW/TdeT0qENxznUi3gaRBXatfYUC1cEYf/60c67j+BFEhqtraKTvjiU0kA/DLoo6HOdcJ+IJIsOtrNrPVFvFgf7nQeFpUYfjnOtEPEFkuKXrN3G+3qHwnCuiDsU518l4gshwB9YtJl9Gd3/+g3Oug3mCyGA1dQ0M3PU6deoGxVOjDsc518mkNUFIukbSekmVkm5LMP8yScsk1UuamWD+aZKqJP0inXFmqre27GMaqzlQNBm6FkYdjnOuk0lbgpCUD9wNXAuMA2ZLGhdXbAswF3gkyWp+ALyUrhgz3fK1bzM2bys9vXsN51wE0nkEMRWoNLONZlYLzAdmxBYws01mthJojF9Y0mRgMPDXNMaY0Wo2LAKg8BxPEM65jpfOBDEE2BozXhVOa5GkPOD/ALe2UO4mSeWSyqurq9scaCY6UlvP6XvKqMnvCWdMiDoc51wnlKmN1F8GFppZVXOFzOxeMys1s9KioqIOCq1jlG3ay0VazeHTp0G+3/DunOt46fzm2QbEPtmmOJyWiouASyV9GegFdJN0yMxOaujOVavXrOLyvB3Ujv1q1KE45zqpdCaIMmCUpBKCxDAL+HQqC5rZ3zcNS5oLlHam5ADQULkYgG6jpkcbiHOu00rbKSYzqwduAZ4B1gKPmVmFpDskXQ8gaYqkKuBG4FeSKtIVTzbZf7SOYfvLONK1HwyKv/DLOec6RlpPbpvZQmBh3LTbY4bLCE49NbeO+4H70xBexnpz424uyqvgyJBL6CFFHY5zrpPK1EbqTm1DxTIGax99xnn33s656HiCyED2btD+4A8Ics5FyRNEhtl96BhnH1rKgYIzoF9J1OE45zoxTxAZ5o2N1VyYt4baYZeAtz845yLkCSLDbFq9hL46TN/xV0UdinOuk/MEkWHyN78MQJcRl0cciXOus/MEkUF2HKhhzJG32NujBE47I+pwnHOdnCeIDPL6hu1MyVtP43A/enDORc97gcsg21a/TA8do+Bcv//BORc9P4LIIAVbX6URkV9yadShOOecJ4hMsXXPEc6tXc6e08ZC935Rh+Occ54gMsWb67cyURvI86uXnHMZwhNEhqiuWEQ3NdDP739wzmUITxAZwMzo+d6r1NMFnXVR1OE45xzgCSIjbNx1mAvqV7Kn3/nQrWfU4TjnHOAJIiOUr93IudpE11FXRB2Kc84d5wkiA+xb+wJ5Mvr68x+ccxnEE0TEGhuNvu8v4ZgKUfGUqMNxzrnjPEFEbP2Og0xqWMXegZOhS7eow3HOueM8QURs+Zq1jMrbRvfRH4w6FOecO0FaE4SkayStl1Qp6bYE8y+TtExSvaSZMdMnSFoiqULSSkmfSmecUTq07kUA+ozz+x+cc5klbQlCUj5wN3AtMA6YLWlcXLEtwFzgkbjpR4DPmNl44BrgZ5L6pivWqNQ3NDJw5xKO5PeG08+LOhznnDtBOntznQpUmtlGAEnzgRnAmqYCZrYpnNcYu6CZvR0z/J6knUARsC+N8Xa4im37mcJq9g2+kB55+VGH45xzJ0jnKaYhwNaY8apwWqtImgp0A95JMO8mSeWSyqurq9scaFQq1qygWLvoPcbbH5xzmafFBCHpY5IiacyWdAbwEPBZM2uMn29m95pZqZmVFhUVdXyAp6jm7aD9ofdYb39wzmWeVL74PwVskPRjSWNase5twNCY8eJwWkoknQb8P+BfzOz1Vmw3K9TWN3L6rjc40GUADBwVdTjOOXeSFhOEmf0DMJHgFM/94dVFN0nq3cKiZcAoSSWSugGzgAWpBBWW/2/gQTN7IpVlss2KrXuYqgoOnnkxSFGH45xzJ0np1JGZHQCeAOYDZwA3AMsk/VMzy9QDtwDPAGuBx8ysQtIdkq4HkDRFUhVwI/ArSRXh4p8ELgPmSloevia0rYqZ6e1VZQzUAfqN9+41nHOZqcWrmMIv888CI4EHgalmtlNSD4Irkv4r2bJmthBYGDft9pjhMoJTT/HL/Q74XYp1yEr1lUH7Qw+/Qc45l6FSucz1E8BPzeyl2IlmdkTS59MTVm6rqWugeF85e7oPoX/fYVGH45xzCaVyimke8GbTiKTukoYDmNnzaYkqxy17t5opWsPR4kuiDsU555JKJUE8DsReYtoQTnNttHHlq5ymoww490NRh+Kcc0mlkiC6mFlt00g47N2OngK9uxiAwnP8AUHOucyVSoKobrrqCEDSDGBX+kLKbYeO1TP84FJ29hgJPQdGHY5zziWVSiP1l4CHJf0CEEH3GZ9Ja1Q5bOk725mm9ewe9g9Rh+Kcc81qMUGY2TvAhZJ6heOH0h5VDqtauZjLVcfA866OOhTnnGtWSr25SvoIMB4oVHjXr5ndkca4clb+5pdoII+Cs/0KJudcZkuls75fEvTH9E8Ep5huBM5Kc1w5af+ROs45vJSdvcdD4WlRh+Occ81KpZH6A2b2GWCvmX0fuAg4J71h5aaytzdzvjZiwy+NOhTnnGtRKgmiJvx7RNKZQB1Bf0yulXaueoEuaqTo/A9HHYpzzrUolTaIp8PHff4EWAYY8Ou0RpWjCra+Qi1d6TZ8WtShOOdci5pNEOGDgp43s33Ak5L+BBSa2f4OiS6HVB88xriat9jZfwLFXbtHHY5zzrWo2VNM4VPc7o4ZP+bJoW2Wrd3A2Lwt5J99edShOOdcSlJpg3he0ickf6rNqdhT8RwARef7/Q/OueyQSoL4IkHnfMckHZB0UNKBNMeVc3pue42j6kGX4slRh+KccylJ5U7qlh4t6lrw3r6jnFe7nOpBpQzLT+neROeci1wqT5S7LNH0+AcIueSWr1rFdXk7eH/Ul6IOxTnnUpbKz9l/jhkuBKYCSwF/VmaKDqx9AYBB5/vzH5xz2aPFNggz+1jM60PAucDeVFYu6RpJ6yVVSrotwfzLJC2TVC9pZty8OZI2hK85qVYo05gZfd9/jYP5fckbPD7qcJxzLmWpNFLHqwLGtlRIUj7BJbLXAuOA2ZLGxRXbAswFHolbtj/wr8A0giOWf5XUrw2xRm7L7sNMaFjJ7qKpkNeWt9s556KRShvEfxHcPQ1BQplAcEd1S6YClWa2MVzPfGAGsKapgJltCuc1xi37YeBZM9sTzn8WuAb4fQrbzSirV5bzEe1l5+grow7FOedaJZU2iPKY4Xrg92b2agrLDSF4uFCTKoIjglQkWnZIfCFJNwE3AQwbNizFVXesw+teBKDI2x+cc1kmlQTxBFBjZg0QnDqS1MPMjqQ3tJaZ2b3AvQClpaXWQvEOZ2YMrF7Cni6D6d9/RNThOOdcq6R0JzUQ23lQd+C5FJbbBgyNGS8Op6XiVJbNGO/sPMCkxtXsP/1C8BvRnXNZJpUEURj7mNFwuEcKy5UBoySVSOoGzAIWpBjXM8DVkvqFjdNXh9Oyyrrlr9FXh+k99qqoQ3HOuVZLJUEcljSpaUTSZOBoSwuZWT1wC8EX+1rgMTOrkHSHpOvDdU2RVEXwlLpfSaoIl90D/IAgyZQBdzQ1WGeTY28H7Q8DzvME4ZzLPqm0QXwNeFzSewSPHD2d4BGkLTKzhcDCuGm3xwyXEZw+SrTsb4DfpLKdTNTYaAze/QY7ug1j8GlnRh2Oc861Wip9MZVJGgOMDietN7O69IaV/dZt28VEW8v7Qz7O4KiDcc65NmjxFJOk/wn0NLPVZrYa6CXpy+kPLbu9s/wleuoY/cf75a3OueyUShvEF8InygFgZnuBL6QvpNxQ/85iGhH9xl0RdSjOOdcmqSSI/NiHBYVdaHRLX0jZr76hkeK9b7K9+yjo0T/qcJxzrk1SSRB/AR6VdKWkKwm6u/hzesPKbhWbtnMBb1NTfEnUoTjnXJulchXTtwi6s2h6mMFKgiuZXBKbl7/ABWpgoD9e1DmXxVLp7rsReAPYRNAB3wcJ7mtwSeRteol68ukzOuGzlpxzLiskPYKQdA4wO3ztAh4FMDNvdW3GsfoGzjpQzrZe53JWt55Rh+Occ23W3BHEOoKjhY+a2SVm9l9AQ8eElb1WbdjMeN6l/qxLow7FOedOSXMJ4uPAduBFSb8OG6i9x7kWvLfiOfJkDJ7g7Q/OueyWNEGY2VNmNgsYA7xI0OXGIEn3SPJvvyS6bnmZYxTQa8RFUYfinHOnJJVG6sNm9oiZfYyg36S3CK5scnGO1jYw8vBStp02Abr4rSLOuezWqockm9leM7vXzPz5mQmsWLeOUdqGlfjVS8657NeqBOGaV70yeI7SmROviTgS55w7dZ4g2lH3qlc4pF50HzYx6lCcc+6UeYJoJwdr6hh99C229yuFvPyow3HOuVPmCaKdrFq9nKGqJv/sy6MOxTnn2oUniHayd1XQ/jBkkrc/OOdygyeIdtLzvdfYm9efgtPHRh2Kc861C08Q7WDvoWOMr13OjgHTQH6zuXMuN6Q1QUi6RtJ6SZWSbkswv0DSo+H8NyQND6d3lfSApFWS1kr6djrjPFUVK16nSAcoPGd61KE451y7SVuCCJ88dzdwLTAOmC1pXFyxzwN7zWwk8FPgR+H0G4ECMzsPmAx8sSl5ZKIDa54HvP3BOZdb0nkEMRWoNLONZlYLzAdmxJWZATwQDj8BXBk+3tSAnpK6AN2BWuBAGmM9JX13LGFnlzPoOmB41KE451y7SWeCGAJsjRmvCqclLGNm9cB+YABBsjhM0JvsFuAuM9sTvwFJN0kql1ReXV3d/jVIwc79hzi3bhW7iy6MZPvOOZcumdpIPZXg2RNnAiXA/5I0Ir5Q2C9UqZmVFhUVdXSMAKxd9jKn6Sg9xnj3VM653JLOBLENGBozXhxOS1gmPJ3UB9gNfBr4i5nVmdlO4FWgNI2xttnRdS8AUDzpwxFH4pxz7SudCaIMGCWpRFI3YBawIK7MAmBOODwTeMHMjOC00gcBJPUELiR4wl3GGVj9BlXdSsjvPSjqUJxzrl2lLUGEbQq3AM8Aa4HHzKxC0h2Srg+L3QcMkFQJfANouhT2bqCXpAqCRPNbM1uZrljbqqp6D+c2rGH/YH84kHMu93RJ58rNbCGwMG7a7THDNQSXtMYvdyjR9ExTufRFilVHn/FXRR2Kc861u0xtpM4KtRsW0UAeZ57vDdTOudzjCaKNzIwz9rzBlsLR5PXoG3U4zjnX7jxBtNHm7TsZ27iBw2d+IOpQnHMuLTxBtNG7S/9KFzXS/9wPRR2Kc86lhSeINmrcuJhjdOWMc/0BQc653OQJog3MjOK9ZWzpcS7q1iPqcJxzLi08QbTBO5u2MJpN1Ay9JOpQnHMubTxBtMHWt/4CwOALro44EuecSx9PEG2gd1/mMN0ZNNqvYHLO5S5PEK3U0GgMP1jOlt4TID+tN6I751ykPEG00oa31zGc7dSfdVnUoTjnXFp5gmil7SueAWDIRO/e2zmX2zxBtFLXLa+wT6fRv2Ri1KE451xaeYJohbr6BkYeWkpVn1LI87fOOZfb/FuuFdaveYvTtQdKvP3BOZf7PEG0wq6VzwJQPPmaiCNxzrn08wTRCt2rXmGniug7ZEzUoTjnXNp5gkhRTW0d5xxdzvb+U0CKOhznnEs7TxApWr9iCf10iPyzp0cdinPOdYi0JghJ10haL6lS0m0J5hdIejSc/4ak4THzzpe0RFKFpFWSCtMZa0v2rX4OgLOmXBtlGM4512HSliAk5VAoy00AABG2SURBVAN3A9cC44DZksbFFfs8sNfMRgI/BX4ULtsF+B3wJTMbD0wH6tIVayp6b3+VqvxiehcNizIM55zrMOk8gpgKVJrZRjOrBeYDM+LKzAAeCIefAK6UJOBqYKWZrQAws91m1pDGWJt15OhRRh9bxc6B06IKwTnnOlw6E8QQYGvMeFU4LWEZM6sH9gMDgHMAk/SMpGWSvploA5JuklQuqby6urrdK9Bk/bLF9NQxCkddkbZtOOdcpsnURuouwCXA34d/b5B0ZXwhM7vXzErNrLSoqChtwRxc+zyNJoaXev9LzrnOI50JYhswNGa8OJyWsEzY7tAH2E1wtPGSme0ysyPAQmBSGmNtVr/3l7Cp6wh69B0UVQjOOdfh0pkgyoBRkkokdQNmAQviyiwA5oTDM4EXzMyAZ4DzJPUIE8flwJo0xprU/gP7OaduLXsGXRTF5p1zLjJpe+KNmdVLuoXgyz4f+I2ZVUi6Ayg3swXAfcBDkiqBPQRJBDPbK+k/CJKMAQvN7P+lK9bmVJY/z2TV02vsB6PYvHPORSatj0Qzs4UEp4dip90eM1wD3Jhk2d8RXOoaqZr1L1Bn+ZRMvirqUJxzrkNlaiN1xhi463U2FoyhoEefqENxzrkO5Q9VbsaeXTsZWV/JsuJ/jDoU5zqduro6qqqqqKmpiTqUnFBYWEhxcTFdu3ZNeRlPEM3YWP5XSmX0GXfSFbbOuTSrqqqid+/eDB8+HHkHmafEzNi9ezdVVVWUlJSkvJyfYmpGXeWLHLVujJgwPepQnOt0ampqGDBggCeHdiCJAQMGtPpozBNEM07f8ybvdD+PLgXdow7FuU7Jk0P7act76QkiiertWyhp3MKRIRdHHYpzzkXCE0QSm8r/AkD/8z4UcSTOuSjs3r2bCRMmMGHCBE4//XSGDBlyfLy2trbZZcvLy/nKV77SQZGmjzdSJ2EbF3GAnow49wNRh+Kci8CAAQNYvnw5APPmzaNXr17ceuutx+fX19fTpUvir9DS0lJKS0s7JM508gSRRPG+ct7pOYGJST4AzrmO8/2nK1jz3oF2Xee4M0/jXz82vlXLzJ07l8LCQt566y0uvvhiZs2axVe/+lVqamro3r07v/3tbxk9ejSLFi3irrvu4k9/+hPz5s1jy5YtbNy4kS1btvC1r30ta44u/NsvgffeXceZtoOtQ+dGHYpzLsNUVVXx2muvkZ+fz4EDB3j55Zfp0qULzz33HN/5znd48sknT1pm3bp1vPjiixw8eJDRo0dz8803t+p+hKh4gkhg27I/cyYw+ALv3tu5TNDaX/rpdOONN5Kfnw/A/v37mTNnDhs2bEASdXWJH3z5kY98hIKCAgoKChg0aBA7duyguLi4I8NuE2+kTiBv88vsoi9njZ4YdSjOuQzTs2fP48Pf+973uOKKK1i9ejVPP/100vsMCgoKjg/n5+dTX1+f9jjbgyeIONbYyPADS3m3dynK87fHOZfc/v37GTIkeFDm/fffH20waeDfgHG2vv0WA9hH4/BLow7FOZfhvvnNb/Ltb3+biRMnZs1RQWsoeD5P9istLbXy8vJTXk/Z/P/NlHU/ouozb1A8Ykw7ROaca4u1a9cyduzYqMPIKYneU0lLzSzhNbl+BBGn29ZX2MZghpSMjjoU55yLlCeIGI31dYw4/BZb+07xPmCcc52eJ4gYmyuW0JsjMOLyqENxzrnIeYKIsWvVswCcNfmaiCNxzrnoeYKI0aPqVTZqGGcMGRZ1KM45F7m0JghJ10haL6lS0m0J5hdIejSc/4ak4XHzh0k6JOnW+GXbW/2xo4w4uort/aeme1POOZcV0pYgJOUDdwPXAuOA2ZLGxRX7PLDXzEYCPwV+FDf/P4A/pyvGWJtWLKa7auky6oqO2JxzLsNdccUVPPPMMydM+9nPfsbNN9+csPz06dNputT+uuuuY9++fSeVmTdvHnfddVez233qqadYs2bN8fHbb7+d5557rrXht4t0HkFMBSrNbKOZ1QLzgRlxZWYAD4TDTwBXKrx8SNLfAe8CFWmM8bh9Fc/RYOLsyVd3xOaccxlu9uzZzJ8//4Rp8+fPZ/bs2S0uu3DhQvr27dum7cYniDvuuIOrrrqqTes6VensrG8IsDVmvAqYlqyMmdVL2g8MkFQDfAv4EJD09JKkm4CbAIYNO7V2g9O2v8qGLqMYUzTolNbjnEuDP98G769q33Wefh5c+8Oks2fOnMl3v/tdamtr6datG5s2beK9997j97//Pd/4xjc4evQoM2fO5Pvf//5Jyw4fPpzy8nIGDhzInXfeyQMPPMCgQYMYOnQokydPBuDXv/419957L7W1tYwcOZKHHnqI5cuXs2DBAhYvXsy//du/8eSTT/KDH/yAj370o8ycOZPnn3+eW2+9lfr6eqZMmcI999xDQUEBw4cPZ86cOTz99NPU1dXx+OOPM2bMqd/om6mN1POAn5rZoeYKmdm9ZlZqZqVFRUVt3ljt4f2UHFtP9UBvf3DOBfr378/UqVP585+Ds9zz58/nk5/8JHfeeSfl5eWsXLmSxYsXs3LlyqTrWLp0KfPnz2f58uUsXLiQsrKy4/M+/vGPU1ZWxooVKxg7diz33XcfH/jAB7j++uv5yU9+wvLlyzn77LOPl6+pqWHu3Lk8+uijrFq1ivr6eu65557j8wcOHMiyZcu4+eabWzyNlap0HkFsA4bGjBeH0xKVqZLUBegD7CY40pgp6cdAX6BRUo2Z/SIdgW566znOUQOF51yZjtU7505VM7/006npNNOMGTOYP38+9913H4899hj33nsv9fX1bN++nTVr1nD++ecnXP7ll1/mhhtuoEePHgBcf/31x+etXr2a7373u+zbt49Dhw7x4Q83/3iB9evXU1JSwjnnnAPAnDlzuPvuu/na174GBAkHYPLkyfzhD3845bpDehNEGTBKUglBIpgFfDquzAJgDrAEmAm8YEHnUMd7ypM0DziUruQAcGjtCxyzLowq/WC6NuGcy0IzZszg61//OsuWLePIkSP079+fu+66i7KyMvr168fcuXOTdvHdkrlz5/LUU09xwQUXcP/997No0aJTirWpS/H27E48baeYzKweuAV4BlgLPGZmFZLukNSURu8jaHOoBL4BnHQpbEfot2MJ67uOpW+ftjUqOedyU69evbjiiiv43Oc+x+zZszlw4AA9e/akT58+7Nix4/jpp2Quu+wynnrqKY4ePcrBgwd5+umnj887ePAgZ5xxBnV1dTz88MPHp/fu3ZuDBw+etK7Ro0ezadMmKisrAXjooYe4/PL09vqQ1ifKmdlCYGHctNtjhmuAG1tYx7y0BBeq2V9NSf07LB7yhXRuxjmXpWbPns0NN9zA/PnzGTNmDBMnTmTMmDEMHTqUiy++uNllJ02axKc+9SkuuOACBg0axJQpU47P+8EPfsC0adMoKipi2rRpx5PCrFmz+MIXvsDPf/5znnjiiePlCwsL+e1vf8uNN954vJH6S1/6UnoqHer03X1X76rmucd/yZhpH2LipAvTEJlzri28u+/219ruvjv9M6mLBhYx++bvRR2Gc85lnEy9zNU551zEPEE45zJWrpwCzwRteS89QTjnMlJhYSG7d+/2JNEOzIzdu3dTWFjYquU6fRuEcy4zFRcXU1VVRXV1ddSh5ITCwkKKi4tbtYwnCOdcRuratSslJSVRh9Gp+Skm55xzCXmCcM45l5AnCOeccwnlzJ3UkqqBzaewioHArnYKJ0q5Ug/wumSqXKlLrtQDTq0uZ5lZwucl5EyCOFWSypPdbp5NcqUe4HXJVLlSl1ypB6SvLn6KyTnnXEKeIJxzziXkCeJv7o06gHaSK/UAr0umypW65Eo9IE118TYI55xzCfkRhHPOuYQ8QTjnnEuo0ycISddIWi+pUlIkz8RuLUmbJK2StFxSeTitv6RnJW0I//YLp0vSz8P6rZQ0KeLYfyNpp6TVMdNaHbukOWH5DZLmZEg95knaFu6X5ZKui5n37bAe6yV9OGZ65J8/SUMlvShpjaQKSV8Np2fVfmmmHlm3XyQVSnpT0oqwLt8Pp5dIeiOM61FJ3cLpBeF4ZTh/eEt1TImZddoXkA+8A4wAugErgHFRx5VC3JuAgXHTfgzcFg7fBvwoHL4O+DMg4ELgjYhjvwyYBKxua+xAf2Bj+LdfONwvA+oxD7g1Qdlx4WerACgJP3P5mfL5A84AJoXDvYG3w5izar80U4+s2y/he9srHO4KvBG+148Bs8LpvwRuDoe/DPwyHJ4FPNpcHVONo7MfQUwFKs1so5nVAvOBGRHH1FYzgAfC4QeAv4uZ/qAFXgf6SjojigABzOwlYE/c5NbG/mHgWTPbY2Z7gWeBa9If/d8kqUcyM4D5ZnbMzN4FKgk+exnx+TOz7Wa2LBw+CKwFhpBl+6WZeiSTsfslfG8PhaNdw5cBHwSeCKfH75OmffUEcKUkkbyOKensCWIIsDVmvIrmP1CZwoC/Sloq6aZw2mAz2x4Ovw8MDoezoY6tjT2T63RLeNrlN02nZMiieoSnJiYS/GLN2v0SVw/Iwv0iKV/ScmAnQbJ9B9hnZvUJ4joeczh/PzCAU6xLZ08Q2eoSM5sEXAv8T0mXxc604NgyK69fzubYgXuAs4EJwHbg/0QbTutI6gU8CXzNzA7Ezsum/ZKgHlm5X8yswcwmAMUEv/rHdHQMnT1BbAOGxowXh9MympltC//uBP6b4MOzo+nUUfh3Z1g8G+rY2tgzsk5mtiP8p24Efs3fDuUzvh6SuhJ8qT5sZn8IJ2fdfklUj2zeLwBmtg94EbiI4HRe04PeYuM6HnM4vw+wm1OsS2dPEGXAqPDKgG4EjTsLIo6pWZJ6SurdNAxcDawmiLvpqpE5wB/D4QXAZ8IrTy4E9secNsgUrY39GeBqSf3C0wVXh9MiFde2cwPBfoGgHrPCK01KgFHAm2TI5y88V30fsNbM/iNmVlbtl2T1yMb9IqlIUt9wuDvwIYI2lReBmWGx+H3StK9mAi+ER33J6piajmyZz8QXwRUZbxOc3/uXqONJId4RBFclrAAqmmImON/4PLABeA7ob3+7GuLusH6rgNKI4/89wWF+HcH50M+3JXbgcwQNbpXAZzOkHg+Fca4M/zHPiCn/L2E91gPXZtLnD7iE4PTRSmB5+Lou2/ZLM/XIuv0CnA+8Fca8Grg9nD6C4Au+EngcKAinF4bjleH8ES3VMZWXd7XhnHMuoc5+isk551wSniCcc84l5AnCOedcQp4gnHPOJeQJwjnnXEKeIJwLSToU/h0u6dPtvO7vxI2/1p7rdy4dPEE4d7LhQKsSRMzdrcmckCDM7AOtjMm5DucJwrmT/RC4NHx2wNfDTtN+Iqks7PDtiwCSpkt6WdICYE047amwE8WKpo4UJf0Q6B6u7+FwWtPRisJ1r1bwjI9Pxax7kaQnJK2T9HB4pzCSfqjgmQcrJd3V4e+O6zRa+tXjXGd0G8HzAz4KEH7R7zezKZIKgFcl/TUsOwk414KulAE+Z2Z7wu4RyiQ9aWa3SbrFgo7X4n2coBO5C4CB4TIvhfMmAuOB94BXgYslrSXoLmKMmVlTdwzOpYMfQTjXsqsJ+h5aTtB99ACCPm0A3oxJDgBfkbQCeJ2gk7RRNO8S4PcWdCa3A1gMTIlZd5UFncwtJzj1tR+oAe6T9HHgyCnXzrkkPEE41zIB/2RmE8JXiZk1HUEcPl5Img5cBVxkZhcQ9KVTeArbPRYz3AB0saCv/6kED4X5KPCXU1i/c83yBOHcyQ4SPLKyyTPAzWFX0kg6J+xJN14fYK+ZHZE0huARkU3qmpaP8zLwqbCdo4jgUaZJe9sMn3XQx8wWAl8nODXlXFp4G4RzJ1sJNISniu4H/pPg9M6ysKG4mr896jHWX4Avhe0E6wlOMzW5F1gpaZmZ/X3M9P8m6Od/BUFPpN80s/fDBJNIb+CPkgoJjmy+0bYqOtcy783VOedcQn6KyTnnXEKeIJxzziXkCcI551xCniCcc84l5AnCOedcQp4gnHPOJeQJwjnnXEL/HzOSqB+c7fNLAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcXqpx0v6X52"
      },
      "source": [
        "### Part (c) -- 10%\n",
        "**Write** a function `make_prediction` that takes as parameters\n",
        "a PyTorchMLP model and sentence (a list of words), and produces\n",
        "a prediction for the next word in the sentence.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2jOK7B26X52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c17d517-8a88-48d8-d9a8-71c1a7b812ea"
      },
      "source": [
        "def make_prediction_torch(model, sentence):\n",
        "    \"\"\"\n",
        "    Use the model to make a prediction for the next word in the\n",
        "    sentence using the last 3 words (sentence[:-3]). You may assume\n",
        "    that len(sentence) >= 3 and that `model` is an instance of\n",
        "    PYTorchMLP.\n",
        "\n",
        "    This function should return the next word, represented as a string.\n",
        "\n",
        "    Example call:\n",
        "    >>> make_prediction_torch(pytorch_mlp, ['you', 'are', 'a'])\n",
        "    \"\"\"\n",
        "    global vocab_stoi, vocab_itos\n",
        "    #  Write your code here\n",
        "    # Prepare data\n",
        "    n_class = 250\n",
        "    sent_i = [vocab_stoi[word] for word in sentence]\n",
        "    data_encode_idx = 0\n",
        "    data_encode = np.zeros((len(sent_i), n_class))\n",
        "    for idx, val in enumerate(sent_i):\n",
        "        data_encode[idx, val] = 1.0\n",
        "    data_encode = data_encode.reshape(-1)\n",
        "\n",
        "    xt = torch.Tensor(data_encode)\n",
        "#    st = torch.Tensor(st).long()\n",
        "\n",
        "    y_hat = model(xt)\n",
        "    # retrieve numpy array\n",
        "#    print(f'y_hat.shape: {y_hat.shape}')\n",
        "#    print(f'type(y_hat): {type(y_hat)}')\n",
        "    pred = y_hat.data.max(1, keepdim=True)[1]\n",
        "    pred = pred.detach().numpy()\n",
        "    t = pred[0][0]\n",
        "    #print(f'pred[0] {pred[0][0]}')\n",
        "    p_word = vocab_itos[pred[0][0]]\n",
        "    print(f'pred[0] {pred[0][0]}, p_word {p_word}')\n",
        "\n",
        "make_prediction_torch(pytorch_mlp, np.array(['you', 'are', 'a']))"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred[0] 6, p_word .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHvIKjYg6X53"
      },
      "source": [
        "### Part (d) -- 10%\n",
        "\n",
        "Use your code to predict what the next word should be in each\n",
        "of the following sentences:\n",
        "\n",
        "- \"You are a\"\n",
        "- \"few companies show\"\n",
        "- \"There are no\"\n",
        "- \"yesterday i was\"\n",
        "- \"the game had\"\n",
        "- \"yesterday the federal\"\n",
        "\n",
        "Do your predictions make sense?\n",
        "\n",
        "In many cases where you overfit the model can either output the same results for all inputs or just memorize the dataset. \n",
        "\n",
        "**Print** the output for all of these sentences and \n",
        "**Write** below if you encounter these effects or something else which indicates overfitting, if you do train again with better hyperparameters.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdzhshY56X53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54656762-97b1-4235-c404-f36cba9620ae"
      },
      "source": [
        "# Write your code here\n",
        "sentences_set = [\"You are a\",\n",
        "                 \"few companies show\",\n",
        "                 \"There are no\",\n",
        "                 \"yesterday i was\",\n",
        "                 \"the game had\",\n",
        "                 \"yesterday the federal\"]\n",
        "print(vocab_stoi)\n",
        "for sent in sentences_set:\n",
        "    words = sent.split()\n",
        "    sentence = [word.lower() for word in words]\n",
        "    make_prediction_torch(pytorch_mlp, np.array(sentence))\n"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'$': 0, \"'s\": 1, ')': 2, ',': 3, '-': 4, '--': 5, '.': 6, ':': 7, ';': 8, '?': 9, 'a': 10, 'about': 11, 'after': 12, 'against': 13, 'ago': 14, 'all': 15, 'also': 16, 'american': 17, 'among': 18, 'an': 19, 'and': 20, 'another': 21, 'any': 22, 'are': 23, 'around': 24, 'as': 25, 'at': 26, 'back': 27, 'be': 28, 'because': 29, 'been': 30, 'before': 31, 'being': 32, 'best': 33, 'between': 34, 'big': 35, 'both': 36, 'business': 37, 'but': 38, 'by': 39, 'called': 40, 'can': 41, 'case': 42, 'center': 43, 'children': 44, 'city': 45, 'come': 46, 'companies': 47, 'company': 48, 'could': 49, 'country': 50, 'court': 51, 'day': 52, 'days': 53, 'department': 54, 'did': 55, 'director': 56, 'do': 57, 'does': 58, 'down': 59, 'dr.': 60, 'during': 61, 'each': 62, 'end': 63, 'even': 64, 'every': 65, 'family': 66, 'federal': 67, 'few': 68, 'first': 69, 'five': 70, 'for': 71, 'former': 72, 'found': 73, 'four': 74, 'from': 75, 'game': 76, 'general': 77, 'get': 78, 'go': 79, 'going': 80, 'good': 81, 'government': 82, 'group': 83, 'had': 84, 'has': 85, 'have': 86, 'he': 87, 'her': 88, 'here': 89, 'high': 90, 'him': 91, 'his': 92, 'home': 93, 'house': 94, 'how': 95, 'i': 96, 'if': 97, 'in': 98, 'including': 99, 'into': 100, 'is': 101, 'it': 102, 'its': 103, 'john': 104, 'just': 105, 'know': 106, 'last': 107, 'law': 108, 'left': 109, 'less': 110, 'life': 111, 'like': 112, 'little': 113, 'long': 114, 'made': 115, 'make': 116, 'man': 117, 'many': 118, 'market': 119, 'may': 120, 'me': 121, 'members': 122, 'might': 123, 'million': 124, 'money': 125, 'more': 126, 'most': 127, 'mr.': 128, 'ms.': 129, 'much': 130, 'music': 131, 'my': 132, 'national': 133, 'never': 134, 'new': 135, 'next': 136, 'night': 137, 'no': 138, 'not': 139, 'now': 140, 'nt': 141, 'of': 142, 'off': 143, 'office': 144, 'officials': 145, 'old': 146, 'on': 147, 'one': 148, 'only': 149, 'or': 150, 'other': 151, 'our': 152, 'out': 153, 'over': 154, 'own': 155, 'part': 156, 'people': 157, 'percent': 158, 'place': 159, 'play': 160, 'police': 161, 'political': 162, 'president': 163, 'program': 164, 'public': 165, 'put': 166, 'right': 167, 'said': 168, 'same': 169, 'say': 170, 'says': 171, 'school': 172, 'season': 173, 'second': 174, 'see': 175, 'set': 176, 'several': 177, 'she': 178, 'should': 179, 'show': 180, 'since': 181, 'so': 182, 'some': 183, 'state': 184, 'states': 185, 'still': 186, 'street': 187, 'such': 188, 'take': 189, 'team': 190, 'than': 191, 'that': 192, 'the': 193, 'their': 194, 'them': 195, 'then': 196, 'there': 197, 'these': 198, 'they': 199, 'think': 200, 'this': 201, 'those': 202, 'though': 203, 'three': 204, 'through': 205, 'time': 206, 'times': 207, 'to': 208, 'today': 209, 'too': 210, 'two': 211, 'under': 212, 'united': 213, 'university': 214, 'until': 215, 'up': 216, 'us': 217, 'use': 218, 'used': 219, 'very': 220, 'want': 221, 'war': 222, 'was': 223, 'way': 224, 'we': 225, 'week': 226, 'well': 227, 'were': 228, 'west': 229, 'what': 230, 'when': 231, 'where': 232, 'which': 233, 'while': 234, 'white': 235, 'who': 236, 'will': 237, 'with': 238, 'without': 239, 'women': 240, 'work': 241, 'world': 242, 'would': 243, 'year': 244, 'years': 245, 'yesterday': 246, 'york': 247, 'you': 248, 'your': 249}\n",
            "pred[0] 6, p_word .\n",
            "pred[0] 6, p_word .\n",
            "pred[0] 6, p_word .\n",
            "pred[0] 6, p_word .\n",
            "pred[0] 6, p_word .\n",
            "pred[0] 6, p_word .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTfh4MwjAlGB"
      },
      "source": [
        "**Write your answers here:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4QBM0fo6X53"
      },
      "source": [
        "### Part (e) -- 6%\n",
        "\n",
        "Report the test accuracy of your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq31oqDR6X53"
      },
      "source": [
        "# Write your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xlr7C8yg6X53"
      },
      "source": [
        "## Question 3. Learning Word Embeddings (24 %)\n",
        "\n",
        "In this section, we will build a slightly different model with a different\n",
        "architecture. In particular, we will first compute a lower-dimensional\n",
        "*representation* of the three words, before using a multi-layer perceptron.\n",
        "\n",
        "Our model will look like this:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=16lXygLTSuRgOCj6UWK0vHkSoyRJWfMSZ\" />\n",
        " \n",
        "\n",
        "This model has 3 layers instead of 2, but the first layer of the network\n",
        "is **not** fully-connected. Instead, we compute the representations of each\n",
        "of the three words **separately**. In addition, the first layer of the network\n",
        "will not use any biases. The reason for this will be clear in question 4.\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0td55ll6X54"
      },
      "source": [
        "### Part (a) -- 10%\n",
        "\n",
        "The PyTorch model is implemented for you. Use \n",
        "`run_pytorch_gradient_descent` to train\n",
        "your PyTorch MLP model to obtain a training accuracy of at least 38%.\n",
        "Plot the learning curve using the `plot_learning_curve` function provided\n",
        "to you, and include your plot in your PDF submission.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqWlfclh6X54"
      },
      "source": [
        "class PyTorchWordEmb(nn.Module):\n",
        "    def __init__(self, emb_size=100, num_hidden=300, vocab_size=250):\n",
        "        super(PyTorchWordEmb, self).__init__()\n",
        "        self.word_emb_layer = nn.Linear(vocab_size, emb_size, bias=False)\n",
        "        self.fc_layer1 = nn.Linear(emb_size * 3, num_hidden)\n",
        "        self.fc_layer2 = nn.Linear(num_hidden, 250)\n",
        "        self.num_hidden = num_hidden\n",
        "        self.emb_size = emb_size\n",
        "    def forward(self, inp):\n",
        "        embeddings = torch.relu(self.word_emb_layer(inp))\n",
        "        embeddings = embeddings.reshape([-1, self.emb_size * 3])\n",
        "        hidden = torch.relu(self.fc_layer1(embeddings))\n",
        "        return self.fc_layer2(hidden)\n",
        "\n",
        "# pytorch_wordemb= PyTorchWordEmb()\n",
        "\n",
        "# result = run_pytorch_gradient_descent(pytorch_wordemb,\n",
        "#                                       max_iters=20000,\n",
        "#                                       ...)\n",
        "\n",
        "# plot_learning_curve(*result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oekGJRad6X54"
      },
      "source": [
        "### Part (b) -- 10%\n",
        "\n",
        "Use the function `make_prediction` that you wrote earlier to predict what the next word should be in each of the following sentences:\n",
        "\n",
        "- \"You are a\"\n",
        "- \"few companies show\"\n",
        "- \"There are no\"\n",
        "- \"yesterday i was\"\n",
        "- \"the game had\"\n",
        "- \"yesterday the federal\"\n",
        "\n",
        "How do these predictions compared to the previous model?\n",
        "\n",
        "**Print** the output for all of these sentences using the new network and \n",
        "**Write** below how the new results compare to the previous ones.\n",
        "\n",
        "Just like before, if you encounter overfitting,\n",
        "train your model for more iterations, or change the hyperparameters in your\n",
        "model. You may need to do this even if your training accuracy is >=38%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1W2Vl3g6X54"
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZQeQXPfGQNB"
      },
      "source": [
        "**Write your explanation here:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g36bTOV46X54"
      },
      "source": [
        "### Part (c) -- 4%\n",
        "\n",
        "Report the test accuracy of your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy8W6XrZ6X54"
      },
      "source": [
        "# Write your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1fyrlDz6X55"
      },
      "source": [
        "## Question 4. Visualizing Word Embeddings (14%)\n",
        "\n",
        "While training the `PyTorchMLP`, we trained the `word_emb_layer`, which takes a one-hot\n",
        "representation of a word in our vocabulary, and returns a low-dimensional vector\n",
        "representation of that word. In this question, we will explore these word embeddings, which are a key concept in natural language processing.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Part (a) -- 4%\n",
        "\n",
        "The code below extracts the **weights** of the word embedding layer,\n",
        "and converts the PyTorch tensor into an numpy array.\n",
        "Explain why each *row* of `word_emb` contains the vector representing\n",
        "of a word. For example `word_emb[vocab_stoi[\"any\"],:]` contains the\n",
        "vector representation of the word \"any\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IvS6JDM6X55"
      },
      "source": [
        "word_emb_weights = list(pytorch_wordemb.word_emb_layer.parameters())[0]\n",
        "word_emb = word_emb_weights.detach().numpy().T\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF_kTjxrkonT"
      },
      "source": [
        "**Write your explanation here:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl-JenYz6X55"
      },
      "source": [
        "### Part (b) -- 5%\n",
        "\n",
        "One interesting thing about these word embeddings is that distances\n",
        "in these vector representations of words make some sense! To show this,\n",
        "we have provided code below that computes the *cosine similarity* of\n",
        "every pair of words in our vocabulary. This measure of similarity between vector ${\\bf v}$ and ${\\bf w}$ is defined as \n",
        "   $$d_{\\rm cos}({\\bf v},{\\bf w}) = \\frac{{\\bf v}^T{\\bf w}}{||{\\bf v}|| ||{\\bf w}||}.$$  We also pre-scale the vectors to have a unit norm, using Numpy's `norm` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPiv3pFX6X55"
      },
      "source": [
        "norms = np.linalg.norm(word_emb, axis=1)\n",
        "word_emb_norm = (word_emb.T / norms).T\n",
        "similarities = np.matmul(word_emb_norm, word_emb_norm.T)\n",
        "\n",
        "# Some example distances. The first one should be larger than the second\n",
        "print(similarities[vocab_stoi['any'], vocab_stoi['many']])\n",
        "print(similarities[vocab_stoi['any'], vocab_stoi['government']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ctM-Mgr6X55"
      },
      "source": [
        "Compute the 5 closest words to the following words:\n",
        "\n",
        "- \"four\"\n",
        "- \"go\"\n",
        "- \"what\"\n",
        "- \"should\"\n",
        "- \"school\"\n",
        "- \"your\"\n",
        "- \"yesterday\"\n",
        "- \"not\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66NCoAE26X55"
      },
      "source": [
        "# Write your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJAOG_pg6X55"
      },
      "source": [
        "### Part (c) -- 5%\n",
        "\n",
        "We can visualize the word embeddings by reducing the dimensionality of\n",
        "the word vectors to 2D. There are many dimensionality reduction techniques\n",
        "that we could use, and we will use an algorithm called t-SNE.\n",
        "(You dont need to know what this is for the assignment; we will cover it later in the course.)\n",
        "Nearby points in this 2-D space are meant to correspond to nearby points\n",
        "in the original, high-dimensional space.\n",
        "\n",
        "The following code runs the t-SNE algorithm and plots the result.\n",
        "\n",
        "Look at the plot and find at least two clusters of related words.\n",
        "\n",
        "**Write** below for each cluster what is the commonality (if there is any) and if they make sense.\n",
        "\n",
        "Note that there is randomness in the initialization of the t-SNE \n",
        "algorithm. If you re-run this code, you may get a different image.\n",
        "Please make sure to submit your image in the PDF file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seD1PgwK6X56"
      },
      "source": [
        "import sklearn.manifold\n",
        "tsne = sklearn.manifold.TSNE()\n",
        "Y = tsne.fit_transform(word_emb)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.xlim(Y[:,0].min(), Y[:, 0].max())\n",
        "plt.ylim(Y[:,1].min(), Y[:, 1].max())\n",
        "for i, w in enumerate(vocab):\n",
        "    plt.text(Y[i, 0], Y[i, 1], w)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%javascript\n",
        "//var kernel = IPython.notebook.kernel;\n",
        "//var thename = window.location.href;\n",
        "//var command = \"notebook_url = \" + \"'\"+thename+\"'\";\n",
        "//kernel.execute(command);\n",
        "//%%javascript\n",
        "//IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')\n",
        "var nb = IPython.notebook;\n",
        "var kernel = IPython.notebook.kernel;\n",
        "var command = \"NOTEBOOK_FULL_PATH = '\" + nb.base_url + nb.notebook_path + \"'\";\n",
        "kernel.execute(command);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "yGb0NyikEmvh",
        "outputId": "a04b995a-b0b9-4130-a813-d8bb31f100b4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "//var kernel = IPython.notebook.kernel;\n",
              "//var thename = window.location.href;\n",
              "//var command = \"notebook_url = \" + \"'\"+thename+\"'\";\n",
              "//kernel.execute(command);\n",
              "//%%javascript\n",
              "//IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')\n",
              "var nb = IPython.notebook;\n",
              "var kernel = IPython.notebook.kernel;\n",
              "var command = \"nb_name = '\" + nb.base_url + nb.notebook_path + \"'\";\n",
              "kernel.execute(command);\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%connect_info\n",
        "#running_servers = !jupyter notebook list\n",
        "#!pip install urllib2\n",
        "#import urllib2\n",
        "#nb_filename = urllib2.url2pathname(notebook_url).split('/')[-1]\n",
        "#if nb_filename.endswith('#'):\n",
        "#    nb_filename = nb_filename[:-1]\n",
        "#nb_name\n",
        "#NOTEBOOK_FULL_PATH\n",
        "\n",
        "#globals()\n",
        "#notebook.notebookapp.list_running_servers()\n",
        "#!pip install ipyparams\n",
        "#!pip install ipynbname\n",
        "#import ipyparams\n",
        "#from IPython.display import display, Javascript\n",
        "\n",
        "#currentNotebook = ipyparams.notebook_name\n",
        "#import ipynbname\n",
        "#nb_name = ipynbname.name()\n",
        "#Path(__file__).name\n",
        "#import IPython ; IPython.extract_module_locals()[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ygx9ukJx-_mm",
        "outputId": "c3694bea-ec90-447a-fb26-ce3399a7fd35"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"shell_port\": 52201,\n",
            "  \"iopub_port\": 39977,\n",
            "  \"stdin_port\": 42647,\n",
            "  \"control_port\": 37611,\n",
            "  \"hb_port\": 41185,\n",
            "  \"ip\": \"127.0.0.1\",\n",
            "  \"key\": \"\",\n",
            "  \"transport\": \"tcp\",\n",
            "  \"signature_scheme\": \"hmac-sha256\",\n",
            "  \"kernel_name\": \"\"\n",
            "}\n",
            "\n",
            "Paste the above JSON into a file, and connect with:\n",
            "    $> jupyter <app> --existing <file>\n",
            "or, if you are local, you can connect with just:\n",
            "    $> jupyter <app> --existing kernel-aaeba0a1-61e1-4f0a-a34f-3bf51170bc83.json\n",
            "or even just:\n",
            "    $> jupyter <app> --existing\n",
            "if this is the most recent Jupyter kernel you have started.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb4gbqMam8S5"
      },
      "source": [
        "**Explain and discuss your results here:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install texlive texlive-xetex texlive-latex-extra pandoc\n",
        "!pip install pypandoc\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp 'drive/My Drive/Colab Notebooks/Assignment2.ipynb' ./\n",
        "\n",
        "!jupyter nbconvert --to PDF \"Assignment2.ipynb\"\n",
        "!ls -la\n",
        "!cp './Assignment2.pdf' 'drive/My Drive/Colab Notebooks'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAdX2kcL9OPF",
        "outputId": "92167f23-7cee-44d0-c2d1-a0b83f618421"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "pandoc is already the newest version (1.19.2.4~dfsg-1build4).\n",
            "pandoc set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono fonts-texgyre\n",
            "  javascript-common libcupsfilters1 libcupsimage2 libgs9 libgs9-common\n",
            "  libijs-0.35 libjbig2dec0 libjs-jquery libkpathsea6 libpotrace0 libptexenc1\n",
            "  libruby2.5 libsynctex1 libtexlua52 libtexluajit2 libzzip-0-13 lmodern\n",
            "  poppler-data preview-latex-style rake ruby ruby-did-you-mean ruby-minitest\n",
            "  ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration t1utils tex-common tex-gyre texlive-base\n",
            "  texlive-binaries texlive-fonts-recommended texlive-latex-base\n",
            "  texlive-latex-recommended texlive-pictures texlive-plain-generic tipa\n",
            "Suggested packages:\n",
            "  fonts-noto apache2 | lighttpd | httpd poppler-utils ghostscript\n",
            "  fonts-japanese-mincho | fonts-ipafont-mincho fonts-japanese-gothic\n",
            "  | fonts-ipafont-gothic fonts-arphic-ukai fonts-arphic-uming fonts-nanum ri\n",
            "  ruby-dev bundler debhelper gv | postscript-viewer perl-tk xpdf-reader\n",
            "  | pdf-viewer texlive-fonts-recommended-doc texlive-latex-base-doc\n",
            "  python-pygments icc-profiles libfile-which-perl\n",
            "  libspreadsheet-parseexcel-perl texlive-latex-extra-doc\n",
            "  texlive-latex-recommended-doc texlive-pstricks dot2tex prerex ruby-tcltk\n",
            "  | libtcltk-ruby texlive-pictures-doc vprerex\n",
            "The following NEW packages will be installed:\n",
            "  fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono fonts-texgyre\n",
            "  javascript-common libcupsfilters1 libcupsimage2 libgs9 libgs9-common\n",
            "  libijs-0.35 libjbig2dec0 libjs-jquery libkpathsea6 libpotrace0 libptexenc1\n",
            "  libruby2.5 libsynctex1 libtexlua52 libtexluajit2 libzzip-0-13 lmodern\n",
            "  poppler-data preview-latex-style rake ruby ruby-did-you-mean ruby-minitest\n",
            "  ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration t1utils tex-common tex-gyre texlive texlive-base\n",
            "  texlive-binaries texlive-fonts-recommended texlive-latex-base\n",
            "  texlive-latex-extra texlive-latex-recommended texlive-pictures\n",
            "  texlive-plain-generic texlive-xetex tipa\n",
            "0 upgraded, 47 newly installed, 0 to remove and 5 not upgraded.\n",
            "Need to get 146 MB of archives.\n",
            "After this operation, 460 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lato all 2.0-2 [2,698 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 poppler-data all 0.4.8-2 [1,479 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 tex-common all 6.09 [33.0 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lmodern all 2.004.5-3 [4,551 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-noto-mono all 20171026-2 [75.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-texgyre all 20160520-1 [8,761 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 javascript-common all 11 [6,066 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsfilters1 amd64 1.20.2-0ubuntu3.1 [108 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsimage2 amd64 2.2.7-1ubuntu2.9 [18.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libijs-0.35 amd64 0.35-13 [15.5 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig2dec0 amd64 0.13-6 [55.9 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9-common all 9.26~dfsg+0-0ubuntu0.18.04.17 [5,092 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9 amd64 9.26~dfsg+0-0ubuntu0.18.04.17 [2,267 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjs-jquery all 3.2.1-1 [152 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkpathsea6 amd64 2017.20170613.44572-8ubuntu0.1 [54.9 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpotrace0 amd64 1.14-2 [17.4 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libptexenc1 amd64 2017.20170613.44572-8ubuntu0.1 [34.5 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 rubygems-integration all 1.11 [4,994 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ruby2.5 amd64 2.5.1-1ubuntu1.12 [48.6 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby amd64 1:2.5.1 [5,712 B]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 rake all 12.3.1-1ubuntu0.1 [44.9 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-did-you-mean all 1.2.0-2 [9,700 B]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-minitest all 5.10.3-1 [38.6 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-power-assert all 0.3.0-1 [7,952 B]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-test-unit all 3.2.5-1 [61.1 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libruby2.5 amd64 2.5.1-1ubuntu1.12 [3,073 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsynctex1 amd64 2017.20170613.44572-8ubuntu0.1 [41.4 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexlua52 amd64 2017.20170613.44572-8ubuntu0.1 [91.2 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexluajit2 amd64 2017.20170613.44572-8ubuntu0.1 [230 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libzzip-0-13 amd64 0.13.62-3.1ubuntu0.18.04.1 [26.0 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic/main amd64 lmodern all 2.004.5-3 [9,631 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic/main amd64 preview-latex-style all 11.91-1ubuntu1 [185 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic/main amd64 t1utils amd64 1.41-2 [56.0 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tex-gyre all 20160520-1 [4,998 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 texlive-binaries amd64 2017.20170613.44572-8ubuntu0.1 [8,179 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-base all 2017.20180305-1 [18.7 MB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-fonts-recommended all 2017.20180305-1 [5,262 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-base all 2017.20180305-1 [951 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-recommended all 2017.20180305-1 [14.9 MB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive all 2017.20180305-1 [14.4 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-pictures all 2017.20180305-1 [4,026 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-latex-extra all 2017.20180305-2 [10.6 MB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-plain-generic all 2017.20180305-2 [23.6 MB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tipa all 2:1.3-20 [2,978 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-xetex all 2017.20180305-1 [10.7 MB]\n",
            "Fetched 146 MB in 8s (19.3 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 123991 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Selecting previously unselected package fonts-lato.\n",
            "Preparing to unpack .../01-fonts-lato_2.0-2_all.deb ...\n",
            "Unpacking fonts-lato (2.0-2) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../02-poppler-data_0.4.8-2_all.deb ...\n",
            "Unpacking poppler-data (0.4.8-2) ...\n",
            "Selecting previously unselected package tex-common.\n",
            "Preparing to unpack .../03-tex-common_6.09_all.deb ...\n",
            "Unpacking tex-common (6.09) ...\n",
            "Selecting previously unselected package fonts-lmodern.\n",
            "Preparing to unpack .../04-fonts-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking fonts-lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../05-fonts-noto-mono_20171026-2_all.deb ...\n",
            "Unpacking fonts-noto-mono (20171026-2) ...\n",
            "Selecting previously unselected package fonts-texgyre.\n",
            "Preparing to unpack .../06-fonts-texgyre_20160520-1_all.deb ...\n",
            "Unpacking fonts-texgyre (20160520-1) ...\n",
            "Selecting previously unselected package javascript-common.\n",
            "Preparing to unpack .../07-javascript-common_11_all.deb ...\n",
            "Unpacking javascript-common (11) ...\n",
            "Selecting previously unselected package libcupsfilters1:amd64.\n",
            "Preparing to unpack .../08-libcupsfilters1_1.20.2-0ubuntu3.1_amd64.deb ...\n",
            "Unpacking libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Selecting previously unselected package libcupsimage2:amd64.\n",
            "Preparing to unpack .../09-libcupsimage2_2.2.7-1ubuntu2.9_amd64.deb ...\n",
            "Unpacking libcupsimage2:amd64 (2.2.7-1ubuntu2.9) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../10-libijs-0.35_0.35-13_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-13) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../11-libjbig2dec0_0.13-6_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.13-6) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../12-libgs9-common_9.26~dfsg+0-0ubuntu0.18.04.17_all.deb ...\n",
            "Unpacking libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.17) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../13-libgs9_9.26~dfsg+0-0ubuntu0.18.04.17_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.17) ...\n",
            "Selecting previously unselected package libjs-jquery.\n",
            "Preparing to unpack .../14-libjs-jquery_3.2.1-1_all.deb ...\n",
            "Unpacking libjs-jquery (3.2.1-1) ...\n",
            "Selecting previously unselected package libkpathsea6:amd64.\n",
            "Preparing to unpack .../15-libkpathsea6_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libpotrace0.\n",
            "Preparing to unpack .../16-libpotrace0_1.14-2_amd64.deb ...\n",
            "Unpacking libpotrace0 (1.14-2) ...\n",
            "Selecting previously unselected package libptexenc1:amd64.\n",
            "Preparing to unpack .../17-libptexenc1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package rubygems-integration.\n",
            "Preparing to unpack .../18-rubygems-integration_1.11_all.deb ...\n",
            "Unpacking rubygems-integration (1.11) ...\n",
            "Selecting previously unselected package ruby2.5.\n",
            "Preparing to unpack .../19-ruby2.5_2.5.1-1ubuntu1.12_amd64.deb ...\n",
            "Unpacking ruby2.5 (2.5.1-1ubuntu1.12) ...\n",
            "Selecting previously unselected package ruby.\n",
            "Preparing to unpack .../20-ruby_1%3a2.5.1_amd64.deb ...\n",
            "Unpacking ruby (1:2.5.1) ...\n",
            "Selecting previously unselected package rake.\n",
            "Preparing to unpack .../21-rake_12.3.1-1ubuntu0.1_all.deb ...\n",
            "Unpacking rake (12.3.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package ruby-did-you-mean.\n",
            "Preparing to unpack .../22-ruby-did-you-mean_1.2.0-2_all.deb ...\n",
            "Unpacking ruby-did-you-mean (1.2.0-2) ...\n",
            "Selecting previously unselected package ruby-minitest.\n",
            "Preparing to unpack .../23-ruby-minitest_5.10.3-1_all.deb ...\n",
            "Unpacking ruby-minitest (5.10.3-1) ...\n",
            "Selecting previously unselected package ruby-net-telnet.\n",
            "Preparing to unpack .../24-ruby-net-telnet_0.1.1-2_all.deb ...\n",
            "Unpacking ruby-net-telnet (0.1.1-2) ...\n",
            "Selecting previously unselected package ruby-power-assert.\n",
            "Preparing to unpack .../25-ruby-power-assert_0.3.0-1_all.deb ...\n",
            "Unpacking ruby-power-assert (0.3.0-1) ...\n",
            "Selecting previously unselected package ruby-test-unit.\n",
            "Preparing to unpack .../26-ruby-test-unit_3.2.5-1_all.deb ...\n",
            "Unpacking ruby-test-unit (3.2.5-1) ...\n",
            "Selecting previously unselected package libruby2.5:amd64.\n",
            "Preparing to unpack .../27-libruby2.5_2.5.1-1ubuntu1.12_amd64.deb ...\n",
            "Unpacking libruby2.5:amd64 (2.5.1-1ubuntu1.12) ...\n",
            "Selecting previously unselected package libsynctex1:amd64.\n",
            "Preparing to unpack .../28-libsynctex1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexlua52:amd64.\n",
            "Preparing to unpack .../29-libtexlua52_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexluajit2:amd64.\n",
            "Preparing to unpack .../30-libtexluajit2_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libzzip-0-13:amd64.\n",
            "Preparing to unpack .../31-libzzip-0-13_0.13.62-3.1ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package lmodern.\n",
            "Preparing to unpack .../32-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package preview-latex-style.\n",
            "Preparing to unpack .../33-preview-latex-style_11.91-1ubuntu1_all.deb ...\n",
            "Unpacking preview-latex-style (11.91-1ubuntu1) ...\n",
            "Selecting previously unselected package t1utils.\n",
            "Preparing to unpack .../34-t1utils_1.41-2_amd64.deb ...\n",
            "Unpacking t1utils (1.41-2) ...\n",
            "Selecting previously unselected package tex-gyre.\n",
            "Preparing to unpack .../35-tex-gyre_20160520-1_all.deb ...\n",
            "Unpacking tex-gyre (20160520-1) ...\n",
            "Selecting previously unselected package texlive-binaries.\n",
            "Preparing to unpack .../36-texlive-binaries_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package texlive-base.\n",
            "Preparing to unpack .../37-texlive-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-fonts-recommended.\n",
            "Preparing to unpack .../38-texlive-fonts-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-base.\n",
            "Preparing to unpack .../39-texlive-latex-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-recommended.\n",
            "Preparing to unpack .../40-texlive-latex-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive.\n",
            "Preparing to unpack .../41-texlive_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-pictures.\n",
            "Preparing to unpack .../42-texlive-pictures_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-pictures (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-extra.\n",
            "Preparing to unpack .../43-texlive-latex-extra_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-latex-extra (2017.20180305-2) ...\n",
            "Selecting previously unselected package texlive-plain-generic.\n",
            "Preparing to unpack .../44-texlive-plain-generic_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-plain-generic (2017.20180305-2) ...\n",
            "Selecting previously unselected package tipa.\n",
            "Preparing to unpack .../45-tipa_2%3a1.3-20_all.deb ...\n",
            "Unpacking tipa (2:1.3-20) ...\n",
            "Selecting previously unselected package texlive-xetex.\n",
            "Preparing to unpack .../46-texlive-xetex_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-xetex (2017.20180305-1) ...\n",
            "Setting up libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.17) ...\n",
            "Setting up libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libjs-jquery (3.2.1-1) ...\n",
            "Setting up libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Setting up libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up tex-common (6.09) ...\n",
            "update-language: texlive-base not installed and configured, doing nothing!\n",
            "Setting up poppler-data (0.4.8-2) ...\n",
            "Setting up tex-gyre (20160520-1) ...\n",
            "Setting up preview-latex-style (11.91-1ubuntu1) ...\n",
            "Setting up fonts-texgyre (20160520-1) ...\n",
            "Setting up fonts-noto-mono (20171026-2) ...\n",
            "Setting up fonts-lato (2.0-2) ...\n",
            "Setting up libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Setting up libcupsimage2:amd64 (2.2.7-1ubuntu2.9) ...\n",
            "Setting up libjbig2dec0:amd64 (0.13-6) ...\n",
            "Setting up ruby-did-you-mean (1.2.0-2) ...\n",
            "Setting up t1utils (1.41-2) ...\n",
            "Setting up ruby-net-telnet (0.1.1-2) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-13) ...\n",
            "Setting up rubygems-integration (1.11) ...\n",
            "Setting up libpotrace0 (1.14-2) ...\n",
            "Setting up javascript-common (11) ...\n",
            "Setting up ruby-minitest (5.10.3-1) ...\n",
            "Setting up libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Setting up libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.17) ...\n",
            "Setting up libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-lmodern (2.004.5-3) ...\n",
            "Setting up ruby-power-assert (0.3.0-1) ...\n",
            "Setting up texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n",
            "update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n",
            "Setting up texlive-base (2017.20180305-1) ...\n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R... \n",
            "mktexlsr: Done.\n",
            "tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n",
            "tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n",
            "tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n",
            "tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/config/pdftexconfig.tex\n",
            "Setting up texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-plain-generic (2017.20180305-2) ...\n",
            "Setting up texlive-latex-base (2017.20180305-1) ...\n",
            "Setting up lmodern (2.004.5-3) ...\n",
            "Setting up texlive-latex-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-pictures (2017.20180305-1) ...\n",
            "Setting up tipa (2:1.3-20) ...\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-DEBIAN'... done.\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST'... done.\n",
            "update-fmtutil has updated the following file(s):\n",
            "\t/var/lib/texmf/fmtutil.cnf-DEBIAN\n",
            "\t/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST\n",
            "If you want to activate the changes in the above file(s),\n",
            "you should run fmtutil-sys or fmtutil.\n",
            "Setting up texlive (2017.20180305-1) ...\n",
            "Setting up texlive-latex-extra (2017.20180305-2) ...\n",
            "Setting up texlive-xetex (2017.20180305-1) ...\n",
            "Setting up ruby2.5 (2.5.1-1ubuntu1.12) ...\n",
            "Setting up ruby (1:2.5.1) ...\n",
            "Setting up ruby-test-unit (3.2.5-1) ...\n",
            "Setting up rake (12.3.1-1ubuntu0.1) ...\n",
            "Setting up libruby2.5:amd64 (2.5.1-1ubuntu1.12) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Building format(s) --all.\n",
            "\tThis may take some time... done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pypandoc\n",
            "  Downloading pypandoc-1.10-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: pypandoc\n",
            "Successfully installed pypandoc-1.10\n",
            "Mounted at /content/drive\n",
            "[NbConvertApp] Converting notebook Assignment2.ipynb to PDF\n",
            "[NbConvertApp] Writing 86936 bytes to ./notebook.tex\n",
            "[NbConvertApp] Building PDF\n",
            "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
            "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
            "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
            "[NbConvertApp] PDF successfully created\n",
            "[NbConvertApp] Writing 104524 bytes to Assignment2.pdf\n",
            "total 176\n",
            "drwxr-xr-x 1 root root   4096 Nov 28 20:44 .\n",
            "drwxr-xr-x 1 root root   4096 Nov 28 20:37 ..\n",
            "-rw------- 1 root root  49652 Nov 28 20:44 Assignment2.ipynb\n",
            "-rw-r--r-- 1 root root 104524 Nov 28 20:44 Assignment2.pdf\n",
            "drwxr-xr-x 4 root root   4096 Nov 22 00:13 .config\n",
            "drwx------ 6 root root   4096 Nov 28 20:44 drive\n",
            "drwxr-xr-x 1 root root   4096 Nov 22 00:14 sample_data\n"
          ]
        }
      ]
    }
  ]
}